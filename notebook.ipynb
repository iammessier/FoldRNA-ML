{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87793,"databundleVersionId":11403143,"sourceType":"competition"},{"sourceId":11079080,"sourceType":"datasetVersion","datasetId":6905307}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1618.59847,"end_time":"2025-03-05T10:57:42.059665","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-05T10:30:43.461195","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"304b1916","cell_type":"code","source":"# First install CUDA-compatible dependencies\n!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n\n# Then install torch-geometric\n!pip install torch_geometric \n\n# Verify installation\nimport torch_geometric\nprint(f\"Success! PyG version: {torch_geometric.__version__}\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.298046,"end_time":"2025-03-05T10:30:51.523384","exception":false,"start_time":"2025-03-05T10:30:46.225338","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T20:59:05.605606Z","iopub.execute_input":"2025-03-18T20:59:05.605900Z","iopub.status.idle":"2025-03-18T20:59:24.495016Z","shell.execute_reply.started":"2025-03-18T20:59:05.605868Z","shell.execute_reply":"2025-03-18T20:59:24.494058Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\nCollecting pyg_lib\n  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/pyg_lib-0.4.0%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch_scatter\n  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting torch_sparse\n  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_cluster\n  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting torch_spline_conv\n  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nInstalling collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\nSuccessfully installed pyg_lib-0.4.0+pt21cu121 torch_cluster-1.6.3+pt21cu121 torch_scatter-2.1.2+pt21cu121 torch_sparse-0.6.18+pt21cu121 torch_spline_conv-1.2.2+pt21cu121\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/libpyg.so: undefined symbol: _ZN2at4_ops10zeros_like4callERKNS_6TensorEN3c108optionalINS5_10ScalarTypeEEENS6_INS5_6LayoutEEENS6_INS5_6DeviceEEENS6_IbEENS6_INS5_12MemoryFormatEEE\n  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","output_type":"stream"},{"name":"stdout","text":"Success! PyG version: 2.6.1\n","output_type":"stream"}],"execution_count":1},{"id":"63e3a0fb-2889-4024-8015-fa15807b881a","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2b848eda","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch_geometric.data import Data\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import SAGEConv\nfrom torch_geometric.data import Data, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport random\n\n# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:36.890046Z","iopub.execute_input":"2025-03-18T20:59:36.890476Z","iopub.status.idle":"2025-03-18T20:59:36.900385Z","shell.execute_reply.started":"2025-03-18T20:59:36.890440Z","shell.execute_reply":"2025-03-18T20:59:36.899367Z"},"papermill":{"duration":11.299128,"end_time":"2025-03-05T10:31:02.828407","exception":false,"start_time":"2025-03-05T10:30:51.529279","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"9e3ab2d0","cell_type":"code","source":"MAX_SEQ_LEN = 1024","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:40.514309Z","iopub.execute_input":"2025-03-18T20:59:40.514631Z","iopub.status.idle":"2025-03-18T20:59:40.518359Z","shell.execute_reply.started":"2025-03-18T20:59:40.514606Z","shell.execute_reply":"2025-03-18T20:59:40.517362Z"},"papermill":{"duration":0.010312,"end_time":"2025-03-05T10:31:02.844275","exception":false,"start_time":"2025-03-05T10:31:02.833963","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"494c37f2","cell_type":"code","source":"# Define paths to data files\nTRAIN_SEQUENCES_PATH = \"/kaggle/input/stanford-rna-3d-folding/train_sequences.csv\"\nTRAIN_LABELS_PATH = \"/kaggle/input/stanford-rna-3d-folding/train_labels.csv\"\n# Load data\ntrain_sequences = pd.read_csv(TRAIN_SEQUENCES_PATH)\ntrain_labels = pd.read_csv(TRAIN_LABELS_PATH)\n\nprint(f\"Loaded {len(train_sequences)} RNA sequences and {len(train_labels)} nucleotide labels\")","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:42.359296Z","iopub.execute_input":"2025-03-18T20:59:42.359720Z","iopub.status.idle":"2025-03-18T20:59:42.752797Z","shell.execute_reply.started":"2025-03-18T20:59:42.359686Z","shell.execute_reply":"2025-03-18T20:59:42.751956Z"},"papermill":{"duration":0.309582,"end_time":"2025-03-05T10:31:03.159232","exception":false,"start_time":"2025-03-05T10:31:02.849650","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Loaded 844 RNA sequences and 137095 nucleotide labels\n","output_type":"stream"}],"execution_count":6},{"id":"ae6d478c","cell_type":"code","source":"# Preprocess data\n# 1. Encoding nucleotides\nnucleotide_mapping = {'A': 0, 'C': 1, 'G': 2, 'U': 3}\nreverse_mapping = {0: 'A', 1: 'C', 2: 'G', 3: 'U'}","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:47.407323Z","iopub.execute_input":"2025-03-18T20:59:47.407634Z","iopub.status.idle":"2025-03-18T20:59:47.412334Z","shell.execute_reply.started":"2025-03-18T20:59:47.407610Z","shell.execute_reply":"2025-03-18T20:59:47.411157Z"},"papermill":{"duration":0.011028,"end_time":"2025-03-05T10:31:03.176227","exception":false,"start_time":"2025-03-05T10:31:03.165199","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"020c89fe","cell_type":"code","source":"# 2. Create feature representation for each nucleotide\ndef one_hot_encode(nucleotide):\n    encoding = [0, 0, 0, 0]\n    if nucleotide in nucleotide_mapping:\n        encoding[nucleotide_mapping[nucleotide]] = 1\n    return encoding","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:50.076804Z","iopub.execute_input":"2025-03-18T20:59:50.077100Z","iopub.status.idle":"2025-03-18T20:59:50.080984Z","shell.execute_reply.started":"2025-03-18T20:59:50.077076Z","shell.execute_reply":"2025-03-18T20:59:50.080219Z"},"papermill":{"duration":0.010622,"end_time":"2025-03-05T10:31:03.192426","exception":false,"start_time":"2025-03-05T10:31:03.181804","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"4ffaf906","cell_type":"code","source":"# Function to create a graph from an RNA sequence\ndef sequence_to_graph(sequence, target_id, labels_df=None, max_connections=MAX_SEQ_LEN):\n    \"\"\"\n    Create a graph representation of an RNA sequence.\n    \n    Args:\n        sequence: The RNA sequence\n        target_id: Identifier for the RNA\n        labels_df: Optional dataframe with 3D coordinate labels\n        max_connections: Maximum number of edges to create (to avoid CUDA OOM errors)\n        \n    Returns:\n        PyTorch Geometric Data object\n    \"\"\"\n    # One-hot encode each nucleotide\n    x = [one_hot_encode(nt) for nt in sequence]\n    x = torch.tensor(x, dtype=torch.float)\n    \n    # Create edges - connect adjacent nucleotides (backbone)\n    # and potentially other connections based on domain knowledge\n    edges = []\n    \n    # Always add backbone connections\n    for i in range(len(sequence) - 1):\n        # Connect to next nucleotide (backbone)\n        edges.append([i, i + 1])\n        edges.append([i + 1, i])  # Bidirectional\n    \n    # Add potential base-pairing connections, but limit total edges to avoid OOM\n    edge_count = len(edges)\n    max_additional_edges = max_connections - edge_count\n    \n    if max_additional_edges > 0:\n        potential_base_pairs = []\n        \n        # Identify potential base pairs (A-U, G-C)\n        for i in range(len(sequence)):\n            for j in range(i + 3, len(sequence)):  # Minimum loop size of 3\n                if (sequence[i] == 'A' and sequence[j] == 'U') or \\\n                   (sequence[i] == 'U' and sequence[j] == 'A') or \\\n                   (sequence[i] == 'G' and sequence[j] == 'C') or \\\n                   (sequence[i] == 'C' and sequence[j] == 'G'):\n                    # Store the potential base pair\n                    potential_base_pairs.append((i, j))\n        \n        # Randomly select base pairs if we have too many\n        if len(potential_base_pairs) > max_additional_edges // 2:  # Divide by 2 for bidirectional edges\n            # Shuffle and take only what we can handle\n            random.shuffle(potential_base_pairs)\n            potential_base_pairs = potential_base_pairs[:max_additional_edges // 2]\n        \n        # Add the selected base pairs\n        for i, j in potential_base_pairs:\n            edges.append([i, j])\n            edges.append([j, i])  # Bidirectional\n    \n    # Convert edges to tensor\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    \n    # Get coordinates if available\n    y = None\n    mask = None\n    if labels_df is not None:\n        target_labels = labels_df[labels_df['ID'].str.startswith(target_id + '_')]\n        \n        # Sort by residue ID to match sequence order\n        target_labels = target_labels.sort_values(by='resid')\n        \n        # Check if we have the expected number of residues\n        if len(target_labels) == len(sequence):\n            # Extract coordinates for each residue\n            coordinates = target_labels[['x_1', 'y_1', 'z_1']].values\n            \n            # Create a mask for NaN values (1 for valid, 0 for NaN)\n            valid_mask = ~np.isnan(coordinates).any(axis=1)\n            mask = torch.tensor(valid_mask, dtype=torch.float)\n            \n            # Replace NaN with zeros (we'll mask these during loss calculation)\n            coordinates = np.nan_to_num(coordinates, nan=0.0)\n            \n            y = torch.tensor(coordinates, dtype=torch.float)\n        else:\n            print(f\"Warning: Mismatch in sequence length and label count for {target_id}\")\n    \n    # Create the data object with properly typed target_id (as string)\n    data = Data(x=x, edge_index=edge_index, y=y, mask=mask)\n    \n    # Store target_id as a string attribute\n    data.target_id = str(target_id)\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:53.536339Z","iopub.execute_input":"2025-03-18T20:59:53.536648Z","iopub.status.idle":"2025-03-18T20:59:53.545702Z","shell.execute_reply.started":"2025-03-18T20:59:53.536624Z","shell.execute_reply":"2025-03-18T20:59:53.544849Z"},"papermill":{"duration":0.016647,"end_time":"2025-03-05T10:31:03.214676","exception":false,"start_time":"2025-03-05T10:31:03.198029","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"43f7dccd","cell_type":"code","source":"def create_dataset(sequences_df, labels_df=None):\n    dataset = []\n    skipped_count = 0\n    nan_count = 0\n    \n    for idx, row in tqdm(sequences_df.iterrows(), total=len(sequences_df)):\n        target_id = row['target_id']\n        sequence = row['sequence']\n        \n        # Clean sequence - replace any non-standard nucleotides with 'N'\n        # and count how many non-standard nucleotides there are\n        cleaned_sequence = ''\n        non_standard_count = 0\n        \n        for nt in sequence:\n            if nt in nucleotide_mapping:\n                cleaned_sequence += nt\n            else:\n                cleaned_sequence += 'N'  # Placeholder for non-standard nucleotides\n                non_standard_count += 1\n        \n        # If too many non-standard nucleotides (>10%), skip this sequence\n        if non_standard_count / len(sequence) > 0.1:\n            print(f\"Skipping sequence {target_id} with {non_standard_count} non-standard nucleotides\")\n            skipped_count += 1\n            continue\n        \n        # Create graph\n        graph = sequence_to_graph(cleaned_sequence, target_id, labels_df)\n        \n        # Check if we have labels with many NaN values\n        if labels_df is not None and hasattr(graph, 'mask') and graph.mask is not None:\n            nan_percentage = 1.0 - torch.mean(graph.mask).item()\n            if nan_percentage > 0.5:  # If more than 50% coordinates are NaN\n                print(f\"Warning: Sequence {target_id} has {nan_percentage:.1%} NaN coordinates\")\n                nan_count += 1\n        \n        # Add to dataset if no labels needed or valid labels exist\n        if labels_df is None or graph.y is not None:\n            dataset.append(graph)\n    \n    print(f\"Dataset creation: {skipped_count} sequences skipped due to non-standard nucleotides\")\n    print(f\"Dataset creation: {nan_count} sequences have >50% NaN coordinates\")\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:56.633041Z","iopub.execute_input":"2025-03-18T20:59:56.633326Z","iopub.status.idle":"2025-03-18T20:59:56.639417Z","shell.execute_reply.started":"2025-03-18T20:59:56.633305Z","shell.execute_reply":"2025-03-18T20:59:56.638619Z"},"papermill":{"duration":0.013738,"end_time":"2025-03-05T10:31:03.234649","exception":false,"start_time":"2025-03-05T10:31:03.220911","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"4a61befc","cell_type":"code","source":"\ndata={\n      \"sequence\":train_sequences['sequence'].to_list(),\n      \"temporal_cutoff\": train_sequences['temporal_cutoff'].to_list(),\n      \"description\": train_sequences['description'].to_list(),\n      \"all_sequences\": train_sequences['all_sequences'].to_list(),\n}\nconfig = {\n    \"cutoff_date\": \"2020-01-01\",\n    \"test_cutoff_date\": \"2022-05-01\",\n}","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:59.226037Z","iopub.execute_input":"2025-03-18T20:59:59.226317Z","iopub.status.idle":"2025-03-18T20:59:59.234018Z","shell.execute_reply.started":"2025-03-18T20:59:59.226295Z","shell.execute_reply":"2025-03-18T20:59:59.233207Z"},"papermill":{"duration":0.01469,"end_time":"2025-03-05T10:31:03.254695","exception":false,"start_time":"2025-03-05T10:31:03.240005","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"9b9af616","cell_type":"code","source":"# Split data into train and test\nall_index = np.arange(len(data['sequence']))\ncutoff_date = pd.Timestamp(config['cutoff_date'])\ntest_cutoff_date = pd.Timestamp(config['test_cutoff_date'])\ntrain_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) <= cutoff_date]\ntest_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) > cutoff_date and pd.Timestamp(d) <= test_cutoff_date]","metadata":{"execution":{"iopub.status.busy":"2025-03-18T20:59:59.653335Z","iopub.execute_input":"2025-03-18T20:59:59.653638Z","iopub.status.idle":"2025-03-18T20:59:59.660563Z","shell.execute_reply.started":"2025-03-18T20:59:59.653616Z","shell.execute_reply":"2025-03-18T20:59:59.659675Z"},"papermill":{"duration":0.014197,"end_time":"2025-03-05T10:31:03.274315","exception":false,"start_time":"2025-03-05T10:31:03.260118","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"99a96f48","cell_type":"code","source":"# Create training dataset\ntrain_dataset = create_dataset(train_sequences, train_labels)\nprint(f\"Created {len(train_dataset)} graph data objects for training\")","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:02.013183Z","iopub.execute_input":"2025-03-18T21:00:02.013555Z","iopub.status.idle":"2025-03-18T21:00:29.809091Z","shell.execute_reply.started":"2025-03-18T21:00:02.013516Z","shell.execute_reply":"2025-03-18T21:00:29.808235Z"},"papermill":{"duration":27.849661,"end_time":"2025-03-05T10:31:31.129471","exception":false,"start_time":"2025-03-05T10:31:03.279810","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":" 14%|█▎        | 114/844 [00:03<00:22, 32.93it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1LS2_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 134/844 [00:04<00:21, 32.79it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1P6V_D has 64.7% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 142/844 [00:04<00:21, 32.66it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1QZC_C has 100.0% NaN coordinates\nWarning: Sequence 1R2W_C has 100.0% NaN coordinates\nWarning: Sequence 1QZC_B has 100.0% NaN coordinates\nWarning: Sequence 1QZA_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 146/844 [00:04<00:21, 32.65it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1QZB_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 170/844 [00:05<00:21, 31.86it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1Y1Y_P has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 178/844 [00:05<00:20, 32.10it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1ZC8_Z has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_G has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_J has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_F has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_I has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_H has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 186/844 [00:05<00:20, 32.15it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1X18_D has 100.0% NaN coordinates\nWarning: Sequence 1X18_A has 100.0% NaN coordinates\nWarning: Sequence 1X18_B has 100.0% NaN coordinates\nWarning: Sequence 1ZN1_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 210/844 [00:06<00:19, 31.85it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2BS0_S has 55.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 218/844 [00:06<00:19, 32.05it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2AGN_C has 100.0% NaN coordinates\nWarning: Sequence 2AGN_A has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 238/844 [00:07<00:19, 31.68it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2IY3_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 246/844 [00:07<00:18, 31.72it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2OB7_D has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 282/844 [00:08<00:17, 32.75it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2R1G_C has 100.0% NaN coordinates\nWarning: Sequence 2R1G_A has 100.0% NaN coordinates\nWarning: Sequence 2R1G_X has 100.0% NaN coordinates\nWarning: Sequence 2R1G_F has 100.0% NaN coordinates\nWarning: Sequence 2R1G_B has 100.0% NaN coordinates\nWarning: Sequence 2R1G_E has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▋      | 306/844 [00:09<00:16, 32.51it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 3EQ3_E has 100.0% NaN coordinates\nWarning: Sequence 3EQ3_Y has 100.0% NaN coordinates\nWarning: Sequence 3EP2_B has 100.0% NaN coordinates\nWarning: Sequence 3EP2_D has 100.0% NaN coordinates\nWarning: Sequence 3EQ4_A has 100.0% NaN coordinates\nWarning: Sequence 3EP2_C has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 314/844 [00:09<00:16, 32.26it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 3CW1_v has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 346/844 [00:10<00:16, 30.34it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 3PGW_N has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 426/844 [00:13<00:13, 30.62it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BP has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 442/844 [00:14<00:13, 29.89it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BA has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BH has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BL has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▎    | 452/844 [00:14<00:13, 29.48it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BC has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BK has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_AH has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 463/844 [00:14<00:12, 29.74it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BU has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BQ has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_AF has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BM has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 470/844 [00:15<00:12, 29.12it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4OQ9_3 has 90.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 511/844 [00:16<00:10, 30.56it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 5GAP_U has 90.7% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 582/844 [00:18<00:08, 30.04it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6IV6_G has 55.9% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 593/844 [00:19<00:08, 29.98it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6HYU_D has 66.7% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 617/844 [00:19<00:07, 30.61it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6WB1_C has 68.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 643/844 [00:20<00:06, 29.50it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6Y0C_IN1 has 59.2% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 675/844 [00:21<00:05, 29.77it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6WW6_E has 68.5% NaN coordinates\nWarning: Sequence 6WW6_F has 68.5% NaN coordinates\nWarning: Sequence 6WW6_C has 66.7% NaN coordinates\nWarning: Sequence 7M57_ii has 63.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 683/844 [00:22<00:05, 30.05it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 7M2T_ss has 74.1% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 691/844 [00:22<00:05, 30.16it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 7SLP_R has 54.3% NaN coordinates\nWarning: Sequence 7S3H_R has 70.6% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 789/844 [00:25<00:01, 28.34it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 8P0B_V has 62.5% NaN coordinates\nWarning: Sequence 8P0G_V has 60.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 806/844 [00:26<00:01, 28.33it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 8WT6_E has 67.2% NaN coordinates\nWarning: Sequence 8WT8_F has 62.2% NaN coordinates\nWarning: Sequence 8WT8_E has 67.2% NaN coordinates\nWarning: Sequence 8WT6_F has 62.2% NaN coordinates\nWarning: Sequence 8WT7_E has 67.2% NaN coordinates\nWarning: Sequence 8WT7_F has 62.2% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 844/844 [00:27<00:00, 30.37it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset creation: 0 sequences skipped due to non-standard nucleotides\nDataset creation: 69 sequences have >50% NaN coordinates\nCreated 844 graph data objects for training\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"id":"e68e69e7","cell_type":"code","source":"train_graphs = train_dataset[:len(train_index)]\nval_graphs = train_dataset[:len(train_index)]","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:35.692710Z","iopub.execute_input":"2025-03-18T21:00:35.693007Z","iopub.status.idle":"2025-03-18T21:00:35.696817Z","shell.execute_reply.started":"2025-03-18T21:00:35.692983Z","shell.execute_reply":"2025-03-18T21:00:35.695906Z"},"papermill":{"duration":0.022334,"end_time":"2025-03-05T10:31:31.169176","exception":false,"start_time":"2025-03-05T10:31:31.146842","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"283e2738","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.01648,"end_time":"2025-03-05T10:31:31.202274","exception":false,"start_time":"2025-03-05T10:31:31.185794","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"654e65c9","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.016208,"end_time":"2025-03-05T10:31:31.234830","exception":false,"start_time":"2025-03-05T10:31:31.218622","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7b1d1c87","cell_type":"code","source":"# Define the GNN model\nclass RNAStructurePredictor(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, output_dim=3, num_layers=10, max_seq_len=MAX_SEQ_LEN):\n        super(RNAStructurePredictor, self).__init__()\n        \n        # Initial embedding layer\n        self.embedding = nn.Linear(input_dim, hidden_dim)\n        \n        # SAGEConv layers\n        self.conv_layers = nn.ModuleList()\n        for _ in range(num_layers):\n            self.conv_layers.append(SAGEConv(hidden_dim, hidden_dim))\n        \n        # Output layer for 3D coordinates prediction (x, y, z)\n        self.output = nn.Linear(hidden_dim, output_dim)\n        \n        # Add attention mechanism\n        self.attention = nn.Sequential(\n            nn.Linear(hidden_dim, 1),\n            nn.Sigmoid()\n        )\n        \n        # Position encoding - increase max sequence length\n        self.position_encoder = nn.Embedding(max_seq_len, hidden_dim)\n        \n        # Initialize parameters with Xavier/Glorot\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n        \n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        \n        # Initial embedding\n        x = self.embedding(x)\n        \n        # Add positional information with bounds checking\n        max_pos = self.position_encoder.weight.size(0) - 1  # Maximum allowed index\n        pos = torch.arange(x.size(0), device=x.device)\n        # Clamp position indices to avoid out-of-bounds errors\n        pos = torch.clamp(pos, max=max_pos)\n        x = x + self.position_encoder(pos)\n        \n        # Graph convolution layers\n        for conv in self.conv_layers:\n            x_residual = x\n            x = conv(x, edge_index)\n            x = F.relu(x)\n            x = x + x_residual  # Skip connection\n            x = F.dropout(x, p=0.2, training=self.training)\n        \n        # Apply attention\n        attention_weights = self.attention(x)\n        x = x * attention_weights\n        \n        # Predict 3D coordinates\n        coordinates = self.output(x)\n        \n        return coordinates","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:37.309376Z","iopub.execute_input":"2025-03-18T21:00:37.309695Z","iopub.status.idle":"2025-03-18T21:00:37.317607Z","shell.execute_reply.started":"2025-03-18T21:00:37.309670Z","shell.execute_reply":"2025-03-18T21:00:37.316748Z"},"papermill":{"duration":0.026124,"end_time":"2025-03-05T10:31:31.277204","exception":false,"start_time":"2025-03-05T10:31:31.251080","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"id":"86897e51","cell_type":"code","source":"# Define loss function for 3D coordinate prediction\ndef rmsd_loss(pred, target, mask=None):\n    \"\"\"\n    Root Mean Square Deviation (RMSD) loss function with optional masking for NaN values.\n    Lower RMSD indicates better structural similarity.\n    \n    Args:\n        pred: Predicted coordinates, shape (n_nucleotides, 3)\n        target: Target coordinates, shape (n_nucleotides, 3)\n        mask: Optional mask for valid values, shape (n_nucleotides,)\n    \"\"\"\n    squared_diff = torch.sum((pred - target) ** 2, dim=1)\n    \n    if mask is not None:\n        # Apply mask to consider only valid coordinates\n        # Ensure we don't divide by zero by adding a small epsilon to the sum\n        masked_squared_diff = squared_diff * mask\n        mean_squared_diff = torch.sum(masked_squared_diff) / (torch.sum(mask) + 1e-10)\n    else:\n        mean_squared_diff = torch.mean(squared_diff)\n    \n    rmsd = torch.sqrt(mean_squared_diff)\n    return rmsd","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:41.598943Z","iopub.execute_input":"2025-03-18T21:00:41.599227Z","iopub.status.idle":"2025-03-18T21:00:41.603988Z","shell.execute_reply.started":"2025-03-18T21:00:41.599206Z","shell.execute_reply":"2025-03-18T21:00:41.603100Z"},"papermill":{"duration":0.023929,"end_time":"2025-03-05T10:31:31.317796","exception":false,"start_time":"2025-03-05T10:31:31.293867","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"67f78a9d","cell_type":"code","source":"def calculate_distance_matrix(X,Y,epsilon=1e-4):\n    return (torch.square(X[:,None]-Y[None,:])+epsilon).sum(-1).sqrt()\n\n\ndef dRMSD(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=None):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=~torch.isnan(gt_dm)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n    if d_clamp is not None:\n        rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).clip(0,d_clamp**2)\n    else:\n        rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n\n    return rmsd.sqrt().mean()/Z\n\ndef local_dRMSD(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=30):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=(~torch.isnan(gt_dm))*(gt_dm<d_clamp)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n\n\n    rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n    # rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).sqrt()/Z\n    #rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])/Z\n    return rmsd.sqrt().mean()/Z\n\ndef dRMAE(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=None):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=~torch.isnan(gt_dm)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n    rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])\n\n    return rmsd.mean()/Z\n\nimport torch\n\ndef align_svd_mae(input, target, Z=10):\n    \"\"\"\n    Aligns the input (Nx3) to target (Nx3) using SVD-based Procrustes alignment\n    and computes RMSD loss.\n    \n    Args:\n        input (torch.Tensor): Nx3 tensor representing the input points.\n        target (torch.Tensor): Nx3 tensor representing the target points.\n    \n    Returns:\n        aligned_input (torch.Tensor): Nx3 aligned input.\n        rmsd_loss (torch.Tensor): RMSD loss.\n    \"\"\"\n    assert input.shape == target.shape, \"Input and target must have the same shape\"\n\n    #mask \n    mask=~torch.isnan(target.sum(-1))\n\n    input=input[mask]\n    target=target[mask]\n    \n    # Compute centroids\n    centroid_input = input.mean(dim=0, keepdim=True)\n    centroid_target = target.mean(dim=0, keepdim=True)\n\n    # Center the points\n    input_centered = input - centroid_input.detach()\n    target_centered = target - centroid_target\n\n    # Compute covariance matrix\n    cov_matrix = input_centered.T @ target_centered\n\n    # SVD to find optimal rotation\n    U, S, Vt = torch.svd(cov_matrix)\n\n    # Compute rotation matrix\n    R = Vt @ U.T\n\n    # Ensure a proper rotation (det(R) = 1, no reflection)\n    if torch.det(R) < 0:\n        Vt[-1, :] *= -1\n        R = Vt @ U.T\n\n    # Rotate input\n    aligned_input = (input_centered @ R.T.detach()) + centroid_target.detach()\n\n    # # Compute RMSD loss\n    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n\n    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n    \n    # return aligned_input, rmsd_loss\n    return torch.abs(aligned_input-target).mean()/Z","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:43.603362Z","iopub.execute_input":"2025-03-18T21:00:43.603695Z","iopub.status.idle":"2025-03-18T21:00:43.614371Z","shell.execute_reply.started":"2025-03-18T21:00:43.603667Z","shell.execute_reply":"2025-03-18T21:00:43.613598Z"},"papermill":{"duration":0.028961,"end_time":"2025-03-05T10:31:31.363425","exception":false,"start_time":"2025-03-05T10:31:31.334464","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"0451111d","cell_type":"code","source":"def train(model, train_loader, optimizer, device):\n    model.train()\n    total_loss = 0\n    loss_values = []\n    # Create tqdm progress bar with loss display\n    pbar = tqdm(train_loader, desc='Training')\n    \n    for data in pbar:\n        data = data.to(device)\n        optimizer.zero_grad()\n        \n        # Forward pass\n        pred = model(data)\n        \n        # Calculate loss if labels exist\n        if data.y is not None:\n            # Use mask if available\n            if hasattr(data, 'mask') and data.mask is not None:\n                loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n                # loss = rmsd_loss(pred, data.y, data.mask)\n            else:\n                loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n                # loss = rmsd_loss(pred, data.y)\n                \n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            loss_values.append(loss.item())\n            \n            # Update progress bar with current loss\n            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'smooth loss': np.mean(loss_values[-100:])})\n    \n    avg_loss = total_loss / len(train_loader)\n    return avg_loss\n\ndef validate(model, val_loader, device):\n    model.eval()\n    total_loss = 0\n    \n    # Create tqdm progress bar with loss display\n    pbar = tqdm(val_loader, desc='Validation')\n    \n    with torch.no_grad():\n        for data in pbar:\n            data = data.to(device)\n            pred = model(data)\n            \n            if data.y is not None:\n                # Use mask if available\n                if hasattr(data, 'mask') and data.mask is not None:\n                    loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n                    # loss = rmsd_loss(pred, data.y, data.mask)\n                else:\n                    loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n                    # loss = rmsd_loss(pred, data.y)\n                total_loss += loss.item()\n                \n                # Update progress bar with current loss\n                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    avg_loss = total_loss / len(val_loader)\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:51.541815Z","iopub.execute_input":"2025-03-18T21:00:51.542099Z","iopub.status.idle":"2025-03-18T21:00:51.549988Z","shell.execute_reply.started":"2025-03-18T21:00:51.542077Z","shell.execute_reply":"2025-03-18T21:00:51.549080Z"},"papermill":{"duration":0.026764,"end_time":"2025-03-05T10:31:31.406850","exception":false,"start_time":"2025-03-05T10:31:31.380086","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"816af246","cell_type":"code","source":"# Function to make predictions on test data\ndef predict(model, test_loader, device):\n    model.eval()\n    predictions = {}\n    \n    with torch.no_grad():\n        for data in test_loader:\n            data = data.to(device)\n            pred = model(data)\n            \n            # Store predictions\n            target_id = data.target_id\n            \n            # If we have ground truth and mask, report metrics\n            if hasattr(data, 'y') and data.y is not None:\n                if hasattr(data, 'mask') and data.mask is not None:\n                    loss = rmsd_loss(pred, data.y, data.mask).item()\n                else:\n                    loss = rmsd_loss(pred, data.y).item()\n                print(f\"Prediction for {target_id}, RMSD: {loss:.4f}\")\n            \n            predictions[target_id] = pred.cpu().numpy()\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:54.843776Z","iopub.execute_input":"2025-03-18T21:00:54.844055Z","iopub.status.idle":"2025-03-18T21:00:54.849617Z","shell.execute_reply.started":"2025-03-18T21:00:54.844032Z","shell.execute_reply":"2025-03-18T21:00:54.848615Z"},"papermill":{"duration":0.024284,"end_time":"2025-03-05T10:31:31.447566","exception":false,"start_time":"2025-03-05T10:31:31.423282","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":19},{"id":"b06c8f07","cell_type":"code","source":"# Setup for training\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = 'cuda'\nelif torch.backends.mps.is_available():\n    device = 'mps'\ndevice = torch.device(device)\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:00:57.459958Z","iopub.execute_input":"2025-03-18T21:00:57.460269Z","iopub.status.idle":"2025-03-18T21:00:57.464729Z","shell.execute_reply.started":"2025-03-18T21:00:57.460242Z","shell.execute_reply":"2025-03-18T21:00:57.463770Z"},"papermill":{"duration":0.024356,"end_time":"2025-03-05T10:31:31.488509","exception":false,"start_time":"2025-03-05T10:31:31.464153","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":20},{"id":"6c4de1f8","cell_type":"code","source":"# Create data loaders\ntrain_loader = DataLoader(train_graphs, batch_size=8, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_graphs, batch_size=8, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:01:00.222579Z","iopub.execute_input":"2025-03-18T21:01:00.222876Z","iopub.status.idle":"2025-03-18T21:01:00.228289Z","shell.execute_reply.started":"2025-03-18T21:01:00.222853Z","shell.execute_reply":"2025-03-18T21:01:00.227474Z"},"papermill":{"duration":0.02529,"end_time":"2025-03-05T10:31:31.531080","exception":false,"start_time":"2025-03-05T10:31:31.505790","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"}],"execution_count":21},{"id":"a2df46d5","cell_type":"code","source":"# Initialize model\ninput_dim = 4  # One-hot encoding dimension for nucleotides\nmodel = RNAStructurePredictor(input_dim, hidden_dim=1024, output_dim=3, num_layers=15, max_seq_len=10000).to(device)\nprint(f\"Model initialized with max sequence length of 10000\")","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:01:06.107294Z","iopub.execute_input":"2025-03-18T21:01:06.107650Z","iopub.status.idle":"2025-03-18T21:01:06.942342Z","shell.execute_reply.started":"2025-03-18T21:01:06.107620Z","shell.execute_reply":"2025-03-18T21:01:06.941578Z"},"papermill":{"duration":0.776948,"end_time":"2025-03-05T10:31:32.325519","exception":false,"start_time":"2025-03-05T10:31:31.548571","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Model initialized with max sequence length of 10000\n","output_type":"stream"}],"execution_count":22},{"id":"43456715","cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.00003)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=12)","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:01:09.672729Z","iopub.execute_input":"2025-03-18T21:01:09.673033Z","iopub.status.idle":"2025-03-18T21:01:09.677205Z","shell.execute_reply.started":"2025-03-18T21:01:09.673009Z","shell.execute_reply":"2025-03-18T21:01:09.676375Z"},"papermill":{"duration":0.022683,"end_time":"2025-03-05T10:31:32.365890","exception":false,"start_time":"2025-03-05T10:31:32.343207","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":23},{"id":"432824e8","cell_type":"code","source":"# Training loop\nnum_epochs = 2000\nbest_val_loss = float('inf')\nearly_stopping_patience = 150\nearly_stopping_counter = 0\n\ntrain_losses = []\nval_losses = []\n\nprint(\"Starting training...\")\nfor epoch in range(num_epochs):\n    # Train\n    train_loss = train(model, train_loader, optimizer, device)\n    train_losses.append(train_loss)\n    \n    # Validate\n    val_loss = validate(model, val_loader, device)\n    val_losses.append(val_loss)\n    \n    # Learning rate scheduler\n    scheduler.step(val_loss)\n    \n    # Early stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        early_stopping_counter = 0\n        # Save best model\n        torch.save(model.state_dict(), \"best_rna_structure_model.pt\")\n    else:\n        early_stopping_counter += 1\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Train Loss: {train_loss:.4f}, \"\n          f\"Val Loss: {val_loss:.4f}, \"\n          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n    \n    if early_stopping_counter >= early_stopping_patience:\n        print(f\"Early stopping triggered after {epoch+1} epochs\")\n        break\n\nprint(\"Training completed!\")","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:01:12.167251Z","iopub.execute_input":"2025-03-18T21:01:12.167585Z","iopub.status.idle":"2025-03-18T21:26:48.018043Z","shell.execute_reply.started":"2025-03-18T21:01:12.167549Z","shell.execute_reply":"2025-03-18T21:26:48.017038Z"},"papermill":{"duration":1533.656824,"end_time":"2025-03-05T10:57:06.039421","exception":false,"start_time":"2025-03-05T10:31:32.382597","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:08<00:00,  8.60it/s, loss=7.1510, smooth loss=18.5] \nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.94it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2000, Train Loss: 18.5489, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.56it/s, loss=2.9815, smooth loss=17.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.42it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/2000, Train Loss: 17.6925, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=5.1950, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.54it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/2000, Train Loss: 17.8774, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.73it/s, loss=3.8799, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.68it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/2000, Train Loss: 18.1151, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.91it/s, loss=2.8164, smooth loss=18.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.66it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/2000, Train Loss: 18.5997, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=9.4302, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.19it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/2000, Train Loss: 17.9282, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.12it/s, loss=11.2863, smooth loss=17.8]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.64it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/2000, Train Loss: 17.8089, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=2.7140, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.77it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/2000, Train Loss: 18.1212, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.99it/s, loss=3.2506, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.73it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/2000, Train Loss: 18.1055, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.75it/s, loss=3.2058, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.04it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/2000, Train Loss: 17.9360, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.77it/s, loss=8.1641, smooth loss=18.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.48it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/2000, Train Loss: 18.2748, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.82it/s, loss=5.6264, smooth loss=19.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.40it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/2000, Train Loss: 19.5480, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.91it/s, loss=6.4467, smooth loss=18]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.02it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/2000, Train Loss: 17.9748, Val Loss: 13.3715, LR: 0.000030\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.18it/s, loss=25.5335, smooth loss=18.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.14it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/2000, Train Loss: 18.4801, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.92it/s, loss=21.0850, smooth loss=19]  \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.14it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/2000, Train Loss: 18.9708, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.88it/s, loss=2.0128, smooth loss=17.7] \nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.54it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/2000, Train Loss: 17.7144, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.97it/s, loss=18.0775, smooth loss=19]  \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.15it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/2000, Train Loss: 18.9832, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.64it/s, loss=0.8955, smooth loss=19.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.13it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/2000, Train Loss: 19.1089, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.94it/s, loss=7.6478, smooth loss=18.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.21it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/2000, Train Loss: 18.2845, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.78it/s, loss=2.9936, smooth loss=18]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.30it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/2000, Train Loss: 17.9747, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.07it/s, loss=16.1580, smooth loss=19.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.38it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/2000, Train Loss: 19.2503, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.26it/s, loss=12.1986, smooth loss=18.6]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.92it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/2000, Train Loss: 18.5548, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.93it/s, loss=8.8808, smooth loss=17]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.44it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/2000, Train Loss: 17.0259, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.78it/s, loss=7.8038, smooth loss=19.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/2000, Train Loss: 19.3053, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.95it/s, loss=3.7466, smooth loss=19.2] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.60it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/2000, Train Loss: 19.1864, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.85it/s, loss=16.3719, smooth loss=18.7]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.44it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/2000, Train Loss: 18.6942, Val Loss: 13.3715, LR: 0.000015\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.75it/s, loss=3.1368, smooth loss=18.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.66it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/2000, Train Loss: 18.5485, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.04it/s, loss=1.3284, smooth loss=17.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.46it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28/2000, Train Loss: 17.5395, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.70it/s, loss=1.1960, smooth loss=19.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.46it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/2000, Train Loss: 19.8831, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.08it/s, loss=19.2521, smooth loss=18.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.43it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30/2000, Train Loss: 18.4676, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.68it/s, loss=6.6708, smooth loss=18.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.54it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/2000, Train Loss: 18.7743, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.83it/s, loss=34.9586, smooth loss=17.9]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.59it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32/2000, Train Loss: 17.8974, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.09it/s, loss=7.7592, smooth loss=18.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.60it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33/2000, Train Loss: 18.3678, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.05it/s, loss=6.6550, smooth loss=19.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.62it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34/2000, Train Loss: 19.3318, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.21it/s, loss=21.9965, smooth loss=17.4]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.83it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35/2000, Train Loss: 17.3515, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.18it/s, loss=1.7498, smooth loss=17.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.73it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36/2000, Train Loss: 17.5885, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.95it/s, loss=26.4492, smooth loss=18.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.74it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37/2000, Train Loss: 18.3094, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.36it/s, loss=17.6762, smooth loss=17.6]\nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.48it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38/2000, Train Loss: 17.6109, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.81it/s, loss=5.7311, smooth loss=19.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39/2000, Train Loss: 19.7419, Val Loss: 13.3715, LR: 0.000008\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.99it/s, loss=5.3899, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.54it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40/2000, Train Loss: 18.0563, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.28it/s, loss=12.8253, smooth loss=18.6]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.87it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41/2000, Train Loss: 18.6213, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.86it/s, loss=13.2026, smooth loss=18]  \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.47it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42/2000, Train Loss: 18.0490, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.35it/s, loss=11.6778, smooth loss=18.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.51it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43/2000, Train Loss: 18.3275, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.11it/s, loss=3.2803, smooth loss=17.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.63it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44/2000, Train Loss: 17.5942, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.86it/s, loss=4.3228, smooth loss=18.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.38it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45/2000, Train Loss: 18.2693, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.88it/s, loss=3.7723, smooth loss=18.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.56it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46/2000, Train Loss: 18.7982, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.93it/s, loss=7.8030, smooth loss=18.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.86it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47/2000, Train Loss: 18.5994, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.97it/s, loss=6.9685, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.34it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48/2000, Train Loss: 17.8760, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.76it/s, loss=25.6010, smooth loss=18.4]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.49it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49/2000, Train Loss: 18.4381, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=12.6014, smooth loss=17.6]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.63it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50/2000, Train Loss: 17.6116, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:07<00:00, 10.59it/s, loss=18.6284, smooth loss=18.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.58it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51/2000, Train Loss: 18.5067, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=5.9350, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.62it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52/2000, Train Loss: 18.1100, Val Loss: 13.3715, LR: 0.000004\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.40it/s, loss=10.6145, smooth loss=19.6]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.43it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53/2000, Train Loss: 19.6334, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.99it/s, loss=5.9034, smooth loss=19.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.25it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54/2000, Train Loss: 19.1438, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.93it/s, loss=2.3544, smooth loss=18.2] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.30it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55/2000, Train Loss: 18.1842, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=7.2104, smooth loss=18.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.43it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56/2000, Train Loss: 18.9043, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.68it/s, loss=1.6479, smooth loss=18.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.90it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57/2000, Train Loss: 18.6856, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=14.3530, smooth loss=18.1]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.45it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58/2000, Train Loss: 18.1449, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.06it/s, loss=4.3608, smooth loss=18.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.29it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59/2000, Train Loss: 18.8439, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=2.3710, smooth loss=17.8] \nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.97it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60/2000, Train Loss: 17.7807, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.80it/s, loss=9.5153, smooth loss=18.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.40it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61/2000, Train Loss: 18.3616, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.84it/s, loss=3.0160, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.46it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62/2000, Train Loss: 17.8689, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.73it/s, loss=3.0122, smooth loss=18.3] \nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.37it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63/2000, Train Loss: 18.2574, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.96it/s, loss=9.2709, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.34it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64/2000, Train Loss: 17.8544, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.63it/s, loss=11.8520, smooth loss=19.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.34it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65/2000, Train Loss: 19.4808, Val Loss: 13.3715, LR: 0.000002\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.88it/s, loss=13.7626, smooth loss=19]  \nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.21it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66/2000, Train Loss: 19.0321, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.89it/s, loss=5.7589, smooth loss=17.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.67it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67/2000, Train Loss: 17.6441, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.41it/s, loss=12.3444, smooth loss=17.9]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68/2000, Train Loss: 17.9347, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.59it/s, loss=14.6388, smooth loss=17.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.46it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69/2000, Train Loss: 17.3392, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.74it/s, loss=4.6071, smooth loss=18.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.43it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70/2000, Train Loss: 18.2789, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.06it/s, loss=2.6625, smooth loss=18.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.64it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71/2000, Train Loss: 18.7524, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.01it/s, loss=8.6630, smooth loss=18.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72/2000, Train Loss: 18.4749, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.75it/s, loss=10.3777, smooth loss=18.7]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.47it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73/2000, Train Loss: 18.6620, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.38it/s, loss=4.8827, smooth loss=18.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.56it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74/2000, Train Loss: 18.8183, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.91it/s, loss=12.0415, smooth loss=17.2]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.31it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75/2000, Train Loss: 17.1713, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.49it/s, loss=18.7303, smooth loss=18.1]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.22it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76/2000, Train Loss: 18.0547, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.16it/s, loss=4.6456, smooth loss=17.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.38it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77/2000, Train Loss: 17.6667, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.95it/s, loss=28.9344, smooth loss=17.7]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.41it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78/2000, Train Loss: 17.6506, Val Loss: 13.3715, LR: 0.000001\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.26it/s, loss=5.3188, smooth loss=18.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.25it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 79/2000, Train Loss: 18.5559, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.76it/s, loss=15.7492, smooth loss=18.6]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.40it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 80/2000, Train Loss: 18.6120, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.99it/s, loss=7.4579, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.25it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 81/2000, Train Loss: 18.1390, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.96it/s, loss=6.0599, smooth loss=18.2] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.36it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82/2000, Train Loss: 18.1655, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.86it/s, loss=7.7461, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.59it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 83/2000, Train Loss: 18.1456, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.98it/s, loss=11.5000, smooth loss=18.4]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.42it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 84/2000, Train Loss: 18.4396, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=5.2379, smooth loss=18.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.77it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 85/2000, Train Loss: 18.3955, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.52it/s, loss=2.2321, smooth loss=17.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 86/2000, Train Loss: 17.8016, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.81it/s, loss=5.8281, smooth loss=19]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.39it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 87/2000, Train Loss: 18.9588, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.02it/s, loss=6.3182, smooth loss=19.3] \nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.85it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 88/2000, Train Loss: 19.2568, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.96it/s, loss=12.2130, smooth loss=18.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.31it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89/2000, Train Loss: 18.2652, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.00it/s, loss=4.6643, smooth loss=17.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.32it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 90/2000, Train Loss: 17.7605, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.07it/s, loss=3.3974, smooth loss=17.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.40it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 91/2000, Train Loss: 17.1175, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.85it/s, loss=2.9300, smooth loss=18.2] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.44it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 92/2000, Train Loss: 18.2278, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=2.4008, smooth loss=19.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.28it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 93/2000, Train Loss: 19.1387, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.06it/s, loss=10.5175, smooth loss=17.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.40it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 94/2000, Train Loss: 17.3012, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.53it/s, loss=25.2874, smooth loss=19.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.48it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 95/2000, Train Loss: 19.4691, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.07it/s, loss=3.2803, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.26it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 96/2000, Train Loss: 18.0736, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=5.8048, smooth loss=18.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.33it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 97/2000, Train Loss: 18.4502, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.02it/s, loss=6.1741, smooth loss=18.8] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.39it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 98/2000, Train Loss: 18.7708, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=5.8608, smooth loss=18.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.34it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 99/2000, Train Loss: 18.7003, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.69it/s, loss=4.1958, smooth loss=18.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.61it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 100/2000, Train Loss: 18.5216, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.41it/s, loss=8.9523, smooth loss=18]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.48it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 101/2000, Train Loss: 17.9720, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.09it/s, loss=12.1356, smooth loss=19]  \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.63it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 102/2000, Train Loss: 19.0181, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.96it/s, loss=1.1288, smooth loss=17.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.68it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 103/2000, Train Loss: 17.3676, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.59it/s, loss=9.0872, smooth loss=18]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.66it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 104/2000, Train Loss: 18.0054, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.12it/s, loss=3.9245, smooth loss=19.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.54it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 105/2000, Train Loss: 19.0591, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.20it/s, loss=10.0387, smooth loss=18.2]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.69it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 106/2000, Train Loss: 18.1611, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=12.5621, smooth loss=18.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.09it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 107/2000, Train Loss: 18.2947, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.79it/s, loss=10.8958, smooth loss=19]  \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.67it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 108/2000, Train Loss: 19.0410, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.58it/s, loss=2.9379, smooth loss=18]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.34it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 109/2000, Train Loss: 18.0257, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.67it/s, loss=11.8962, smooth loss=18.9]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.35it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 110/2000, Train Loss: 18.8805, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.61it/s, loss=2.8528, smooth loss=18.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.49it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 111/2000, Train Loss: 18.6408, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=1.1098, smooth loss=18]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.73it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 112/2000, Train Loss: 17.9887, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.14it/s, loss=14.6319, smooth loss=18.6]\nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.68it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 113/2000, Train Loss: 18.6362, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.72it/s, loss=12.4097, smooth loss=18.6]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.74it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 114/2000, Train Loss: 18.5734, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=3.7081, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.64it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 115/2000, Train Loss: 18.1248, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.01it/s, loss=8.1935, smooth loss=18.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.26it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 116/2000, Train Loss: 18.6273, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.58it/s, loss=3.2407, smooth loss=18.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.75it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 117/2000, Train Loss: 18.3515, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.98it/s, loss=2.0948, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.55it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 118/2000, Train Loss: 17.9250, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.25it/s, loss=6.5663, smooth loss=17.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 119/2000, Train Loss: 17.5328, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.60it/s, loss=34.0577, smooth loss=17.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 120/2000, Train Loss: 17.4985, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.96it/s, loss=11.2770, smooth loss=18.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.50it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 121/2000, Train Loss: 18.5270, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.00it/s, loss=10.5080, smooth loss=19.5]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.64it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 122/2000, Train Loss: 19.4897, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.51it/s, loss=1.2976, smooth loss=18.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.53it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 123/2000, Train Loss: 18.5728, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.15it/s, loss=2.4253, smooth loss=19.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.46it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 124/2000, Train Loss: 19.3417, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.88it/s, loss=11.7596, smooth loss=17.1]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.65it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 125/2000, Train Loss: 17.1438, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.01it/s, loss=6.2929, smooth loss=17.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.44it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 126/2000, Train Loss: 17.5810, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.08it/s, loss=8.5302, smooth loss=18.5] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.61it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 127/2000, Train Loss: 18.4776, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.11it/s, loss=11.3402, smooth loss=18.8]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.49it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 128/2000, Train Loss: 18.7688, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=49.9336, smooth loss=19.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.27it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 129/2000, Train Loss: 19.3100, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.92it/s, loss=2.5661, smooth loss=17.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.74it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 130/2000, Train Loss: 17.6528, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.88it/s, loss=8.7111, smooth loss=19.2] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.63it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 131/2000, Train Loss: 19.2072, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.14it/s, loss=9.5819, smooth loss=18.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 19.16it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 132/2000, Train Loss: 18.4171, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.99it/s, loss=33.8673, smooth loss=18.9]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.65it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 133/2000, Train Loss: 18.9068, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.27it/s, loss=2.5367, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.78it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 134/2000, Train Loss: 18.1350, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.88it/s, loss=4.6239, smooth loss=18.1] \nValidation: 100%|██████████| 76/76 [00:04<00:00, 18.93it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 135/2000, Train Loss: 18.1069, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.78it/s, loss=9.6144, smooth loss=18.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.70it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 136/2000, Train Loss: 18.4094, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.17it/s, loss=7.2970, smooth loss=18.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.78it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 137/2000, Train Loss: 18.7280, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.00it/s, loss=9.0461, smooth loss=18]   \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.18it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 138/2000, Train Loss: 18.0189, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.45it/s, loss=16.7542, smooth loss=18.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.48it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 139/2000, Train Loss: 18.2535, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.60it/s, loss=11.9609, smooth loss=18.6]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.19it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 140/2000, Train Loss: 18.5634, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.91it/s, loss=0.4239, smooth loss=17.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.11it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 141/2000, Train Loss: 17.6531, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.76it/s, loss=4.7721, smooth loss=18.4] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.60it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 142/2000, Train Loss: 18.3844, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.40it/s, loss=12.7290, smooth loss=18.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.54it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 143/2000, Train Loss: 18.2901, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.79it/s, loss=11.4677, smooth loss=18.9]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.54it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 144/2000, Train Loss: 18.8604, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.32it/s, loss=2.0507, smooth loss=18.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.36it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 145/2000, Train Loss: 18.6573, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.13it/s, loss=3.7702, smooth loss=18.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.39it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 146/2000, Train Loss: 18.3458, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.95it/s, loss=1.0848, smooth loss=18.7] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.43it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 147/2000, Train Loss: 18.6739, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.75it/s, loss=9.3160, smooth loss=18.3] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.43it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 148/2000, Train Loss: 18.3014, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.55it/s, loss=13.6567, smooth loss=18.3]\nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.38it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 149/2000, Train Loss: 18.3431, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 12.04it/s, loss=6.9316, smooth loss=18.6] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.34it/s, loss=21.8392]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 150/2000, Train Loss: 18.6160, Val Loss: 13.3715, LR: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 76/76 [00:06<00:00, 11.77it/s, loss=1.6645, smooth loss=17.9] \nValidation: 100%|██████████| 76/76 [00:03<00:00, 20.35it/s, loss=21.8392]","output_type":"stream"},{"name":"stdout","text":"Epoch 151/2000, Train Loss: 17.9398, Val Loss: 13.3715, LR: 0.000000\nEarly stopping triggered after 151 epochs\nTraining completed!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":24},{"id":"7701900a","cell_type":"code","source":"# Plot training and validation losses\nplt.figure(figsize=(10, 6))\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('RMSD Loss')\nplt.title('Training and Validation Losses')\nplt.legend()\nplt.grid(True)\nplt.savefig('training_loss.png')\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:26:51.761956Z","iopub.execute_input":"2025-03-18T21:26:51.762274Z","iopub.status.idle":"2025-03-18T21:26:52.020396Z","shell.execute_reply.started":"2025-03-18T21:26:51.762246Z","shell.execute_reply":"2025-03-18T21:26:52.019696Z"},"papermill":{"duration":1.942559,"end_time":"2025-03-05T10:57:09.515781","exception":false,"start_time":"2025-03-05T10:57:07.573222","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":25},{"id":"c9c4f725","cell_type":"code","source":"# Generate multiple conformations for each RNA sequence\ndef generate_multiple_conformations(model, data, num_conformations=5):\n    \"\"\"\n    Generate multiple structural conformations for an RNA sequence.\n    \n    Args:\n        model: The trained GNN model\n        data: Graph data object containing the RNA sequence\n        num_conformations: Number of conformations to generate (default: 5)\n        \n    Returns:\n        List of numpy arrays, each array has shape (n_nucleotides, 3) for x,y,z coordinates\n    \"\"\"\n    model.eval()\n    conformations = []\n    \n    # Set random seed for reproducibility\n    torch.manual_seed(42)\n    \n    with torch.no_grad():\n        # Generate first conformation (deterministic)\n        base_pred = model(data)\n        base_np = base_pred.cpu().numpy()\n        \n        # Check if base prediction contains NaN values\n        if np.isnan(base_np).any():\n            print(\"Warning: Base prediction contains NaN values. Replacing with zeros.\")\n            base_np = np.nan_to_num(base_np, nan=0.0)\n        \n        # Save the base prediction\n        conformations.append(base_np)\n        \n        # Generate additional conformations with controlled variations\n        for i in range(1, num_conformations):\n            # Use different seeds for different conformations\n            torch.manual_seed(42 + i * 100)  # Larger seed increment for more diversity\n            \n            # Create a copy of the base prediction with a small, controlled variation\n            variation = base_np.copy()\n            \n            # Add random noise with small magnitude (1-5% of the coordinate values)\n            # Calculate standard deviation of base coordinates to scale noise appropriately\n            if not np.all(base_np == 0):  # Check if base_np is not all zeros\n                coord_std = max(np.std(base_np), 0.5)  # Use at least 0.5 to avoid too small noise\n                noise_scale = coord_std * 0.05 * (i + 1)  # Increasing noise for each conformation\n            else:\n                # If base prediction is all zeros (which shouldn't happen normally)\n                noise_scale = 0.5 * (i + 1)\n            \n            # Generate noise and ensure it's not NaN\n            noise = np.random.normal(0, noise_scale, size=variation.shape)\n            \n            # Apply noise to create a new conformation\n            variation += noise\n            \n            # Ensure no NaN values\n            variation = np.nan_to_num(variation, nan=0.0)\n            \n            conformations.append(variation)\n    \n    # Double-check that all conformations are valid and contain no NaNs\n    for i, conf in enumerate(conformations):\n        if np.isnan(conf).any():\n            print(f\"Warning: Conformation {i+1} contains NaN values after processing. Replacing with zeros.\")\n            conformations[i] = np.nan_to_num(conf, nan=0.0)\n    \n    return conformations\n\n# Function to make multiple predictions for test data\ndef predict_multiple_conformations(model, test_loader, device, num_conformations=5):\n    predictions = {}\n    \n    for data in test_loader:\n        data = data.to(device)\n        conformations = generate_multiple_conformations(model, data, num_conformations)\n        \n        # Store predictions - ensure target_id is a hashable type (string)\n        # The target_id could be stored as a list or other non-hashable type\n        if hasattr(data, 'target_id'):\n            # Convert to string if it's not already\n            if isinstance(data.target_id, list) and len(data.target_id) > 0:\n                target_id = str(data.target_id[0])  # Take the first element if it's a list\n            else:\n                target_id = str(data.target_id)  # Convert to string to ensure hashability\n        else:\n            # Generate a unique ID if none exists\n            target_id = f\"unknown_target_{len(predictions)}\"\n            \n        print(f\"Processing target: {target_id}\")\n        predictions[target_id] = conformations\n        \n        # If we have ground truth, report metrics for the first conformation\n        if hasattr(data, 'y') and data.y is not None and len(conformations) > 0:\n            first_conf = torch.tensor(conformations[0], device=device)\n            \n            if hasattr(data, 'mask') and data.mask is not None:\n                loss = rmsd_loss(first_conf, data.y, data.mask).item()\n            else:\n                loss = rmsd_loss(first_conf, data.y).item()\n                \n            print(f\"Prediction for {target_id}, RMSD of first conformation: {loss:.4f}\")\n    \n    return predictions\n\n# Example of how to use the prediction function on test data\ndef process_test_data(test_sequences_path):\n    # Load test sequences\n    test_sequences = pd.read_csv(test_sequences_path)\n    \n    # Create test dataset (without labels)\n    test_dataset = create_dataset(test_sequences)\n    \n    # Create test loader\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n    \n    # Make predictions\n    predictions = predict_multiple_conformations(model, test_loader, device)\n    \n    # Format predictions for submission\n    formatted_predictions = []\n    \n    for target_id, conformations in predictions.items():\n        for i, conformation in enumerate(conformations):\n            for j, coords in enumerate(conformation):\n                resid = j + 1  # 1-based indexing\n                row = {\n                    'ID': f\"{target_id}_{resid}\",\n                    f'x_{i+1}': coords[0],\n                    f'y_{i+1}': coords[1],\n                    f'z_{i+1}': coords[2]\n                }\n                formatted_predictions.append(row)\n    \n    # Create submission dataframe\n    submission_df = pd.DataFrame(formatted_predictions)\n    return submission_df","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:27:46.443153Z","iopub.execute_input":"2025-03-18T21:27:46.443484Z","iopub.status.idle":"2025-03-18T21:27:46.456852Z","shell.execute_reply.started":"2025-03-18T21:27:46.443456Z","shell.execute_reply":"2025-03-18T21:27:46.455880Z"},"papermill":{"duration":1.556019,"end_time":"2025-03-05T10:57:12.633958","exception":false,"start_time":"2025-03-05T10:57:11.077939","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":26},{"id":"f0935ba3","cell_type":"code","source":"test_predictions = process_test_data(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")\nsub = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/sample_submission.csv\")\nDF_ROWS = []\n\nfor i, row in sub.iterrows():\n    snap = test_predictions[test_predictions['ID'] == row['ID']]\n    x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5 = snap['x_1'], snap['y_1'], snap['z_1'], snap['x_2'], snap['y_2'], snap['z_2'], snap['x_3'], snap['y_3'], snap['z_3'], snap['x_4'], snap['y_4'], snap['z_4'], snap['x_5'], snap['y_5'], snap['z_5']\n    x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5 = x1.values[0], y1.values[0], z1.values[0], x2.values[1], y2.values[1], z2.values[1], x3.values[2], y3.values[2], z3.values[2], x4.values[3], y4.values[3], z4.values[3], x5.values[4], y5.values[4], z5.values[4]\n    _row = [x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5]\n    DF_ROWS.append(_row)\nsub[['x_1', 'y_1', 'z_1', 'x_2', 'y_2', 'z_2', 'x_3', 'y_3', 'z_3', 'x_4', 'y_4', 'z_4', 'x_5', 'y_5', 'z_5']] = DF_ROWS\nsub.head()\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2025-03-18T21:27:57.564131Z","iopub.execute_input":"2025-03-18T21:27:57.564457Z","iopub.status.idle":"2025-03-18T21:28:01.919337Z","shell.execute_reply.started":"2025-03-18T21:27:57.564429Z","shell.execute_reply":"2025-03-18T21:28:01.918213Z"},"papermill":{"duration":5.782178,"end_time":"2025-03-05T10:57:19.932297","exception":false,"start_time":"2025-03-05T10:57:14.150119","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 12/12 [00:00<00:00, 141.97it/s]\n/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"},{"name":"stdout","text":"Dataset creation: 0 sequences skipped due to non-standard nucleotides\nDataset creation: 0 sequences have >50% NaN coordinates\nProcessing target: R1107\nProcessing target: R1108\nProcessing target: R1116\nProcessing target: R1117v2\nProcessing target: R1126\nProcessing target: R1128\nProcessing target: R1136\nProcessing target: R1138\nProcessing target: R1149\nProcessing target: R1156\nProcessing target: R1189\nProcessing target: R1190\n","output_type":"stream"}],"execution_count":27},{"id":"151d48b2","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.592546,"end_time":"2025-03-05T10:57:23.028318","exception":false,"start_time":"2025-03-05T10:57:21.435772","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"e3659fd2","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.514728,"end_time":"2025-03-05T10:57:26.056614","exception":false,"start_time":"2025-03-05T10:57:24.541886","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f7d09222","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.498665,"end_time":"2025-03-05T10:57:29.067683","exception":false,"start_time":"2025-03-05T10:57:27.569018","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"037b42e2","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.50879,"end_time":"2025-03-05T10:57:32.119464","exception":false,"start_time":"2025-03-05T10:57:30.610674","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"78081bdf","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.589876,"end_time":"2025-03-05T10:57:35.222125","exception":false,"start_time":"2025-03-05T10:57:33.632249","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"747c9258","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.504867,"end_time":"2025-03-05T10:57:38.233557","exception":false,"start_time":"2025-03-05T10:57:36.728690","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}