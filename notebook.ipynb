{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87793,"databundleVersionId":11403143,"sourceType":"competition"},{"sourceId":11079080,"sourceType":"datasetVersion","datasetId":6905307}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1748.533934,"end_time":"2025-03-18T21:59:22.316642","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-18T21:30:13.782708","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"bb860014","cell_type":"code","source":"# First install CUDA-compatible dependencies\n!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n\n# Then install torch-geometric\n!pip install torch_geometric \n\n# Verify installation\nimport torch_geometric\nprint(f\"Success! PyG version: {torch_geometric.__version__}\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-19T21:17:10.762549Z","iopub.execute_input":"2025-03-19T21:17:10.762946Z","iopub.status.idle":"2025-03-19T21:17:18.647086Z","shell.execute_reply.started":"2025-03-19T21:17:10.762913Z","shell.execute_reply":"2025-03-19T21:17:18.646002Z"},"papermill":{"duration":22.7356,"end_time":"2025-03-18T21:30:39.472849","exception":false,"start_time":"2025-03-18T21:30:16.737249","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\nRequirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt21cu121)\nRequirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu121)\nRequirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu121)\nRequirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt21cu121)\nRequirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt21cu121)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nSuccess! PyG version: 2.6.1\n","output_type":"stream"}],"execution_count":73},{"id":"08083c5a","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.008448,"end_time":"2025-03-18T21:30:39.491034","exception":false,"start_time":"2025-03-18T21:30:39.482586","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"6360cfcc","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch_geometric.data import Data\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import SAGEConv\nfrom torch_geometric.data import Data, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport random\n\n# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:18.648730Z","iopub.execute_input":"2025-03-19T21:17:18.649058Z","iopub.status.idle":"2025-03-19T21:17:18.657760Z","shell.execute_reply.started":"2025-03-19T21:17:18.649034Z","shell.execute_reply":"2025-03-19T21:17:18.657000Z"},"papermill":{"duration":1.795738,"end_time":"2025-03-18T21:30:41.295192","exception":false,"start_time":"2025-03-18T21:30:39.499454","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":74},{"id":"b23a90bf","cell_type":"code","source":"MAX_SEQ_LEN = 1024","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:18.659605Z","iopub.execute_input":"2025-03-19T21:17:18.659917Z","iopub.status.idle":"2025-03-19T21:17:18.679735Z","shell.execute_reply.started":"2025-03-19T21:17:18.659883Z","shell.execute_reply":"2025-03-19T21:17:18.678729Z"},"papermill":{"duration":0.014465,"end_time":"2025-03-18T21:30:41.318583","exception":false,"start_time":"2025-03-18T21:30:41.304118","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":75},{"id":"4b35ccc1","cell_type":"code","source":"# Define paths to data files\nTRAIN_SEQUENCES_PATH = \"/kaggle/input/stanford-rna-3d-folding/train_sequences.csv\"\nTRAIN_LABELS_PATH = \"/kaggle/input/stanford-rna-3d-folding/train_labels.csv\"\n# Load data\ntrain_sequences = pd.read_csv(TRAIN_SEQUENCES_PATH)\ntrain_labels = pd.read_csv(TRAIN_LABELS_PATH)\n\nprint(f\"Loaded {len(train_sequences)} RNA sequences and {len(train_labels)} nucleotide labels\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:18.681337Z","iopub.execute_input":"2025-03-19T21:17:18.681587Z","iopub.status.idle":"2025-03-19T21:17:18.945811Z","shell.execute_reply.started":"2025-03-19T21:17:18.681566Z","shell.execute_reply":"2025-03-19T21:17:18.945057Z"},"papermill":{"duration":0.354536,"end_time":"2025-03-18T21:30:41.681259","exception":false,"start_time":"2025-03-18T21:30:41.326723","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Loaded 844 RNA sequences and 137095 nucleotide labels\n","output_type":"stream"}],"execution_count":76},{"id":"1ac513a6","cell_type":"code","source":"# Preprocess data\n# 1. Encoding nucleotides\nnucleotide_mapping = {'A': 0, 'C': 1, 'G': 2, 'U': 3}\nreverse_mapping = {0: 'A', 1: 'C', 2: 'G', 3: 'U'}","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:18.946764Z","iopub.execute_input":"2025-03-19T21:17:18.947042Z","iopub.status.idle":"2025-03-19T21:17:18.951231Z","shell.execute_reply.started":"2025-03-19T21:17:18.947018Z","shell.execute_reply":"2025-03-19T21:17:18.950255Z"},"papermill":{"duration":0.015698,"end_time":"2025-03-18T21:30:41.705752","exception":false,"start_time":"2025-03-18T21:30:41.690054","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":77},{"id":"c2159680","cell_type":"code","source":"# 2. Create feature representation for each nucleotide\ndef one_hot_encode(nucleotide):\n    encoding = [0, 0, 0, 0]\n    if nucleotide in nucleotide_mapping:\n        encoding[nucleotide_mapping[nucleotide]] = 1\n    return encoding","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:18.952144Z","iopub.execute_input":"2025-03-19T21:17:18.952387Z","iopub.status.idle":"2025-03-19T21:17:18.968866Z","shell.execute_reply.started":"2025-03-19T21:17:18.952365Z","shell.execute_reply":"2025-03-19T21:17:18.967887Z"},"papermill":{"duration":0.015969,"end_time":"2025-03-18T21:30:41.730544","exception":false,"start_time":"2025-03-18T21:30:41.714575","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":78},{"id":"e6590b65","cell_type":"code","source":"# Function to create a graph from an RNA sequence\ndef sequence_to_graph(sequence, target_id, labels_df=None, max_connections=MAX_SEQ_LEN):\n    \"\"\"\n    Create a graph representation of an RNA sequence.\n    \n    Args:\n        sequence: The RNA sequence\n        target_id: Identifier for the RNA\n        labels_df: Optional dataframe with 3D coordinate labels\n        max_connections: Maximum number of edges to create (to avoid CUDA OOM errors)\n        \n    Returns:\n        PyTorch Geometric Data object\n    \"\"\"\n    # One-hot encode each nucleotide\n    x = [one_hot_encode(nt) for nt in sequence]\n    x = torch.tensor(x, dtype=torch.float)\n    \n    # Create edges - connect adjacent nucleotides (backbone)\n    # and potentially other connections based on domain knowledge\n    edges = []\n    \n    # Always add backbone connections\n    for i in range(len(sequence) - 1):\n        # Connect to next nucleotide (backbone)\n        edges.append([i, i + 1])\n        edges.append([i + 1, i])  # Bidirectional\n    \n    # Add potential base-pairing connections, but limit total edges to avoid OOM\n    edge_count = len(edges)\n    max_additional_edges = max_connections - edge_count\n    \n    if max_additional_edges > 0:\n        potential_base_pairs = []\n        \n        # Identify potential base pairs (A-U, G-C)\n        for i in range(len(sequence)):\n            for j in range(i + 3, len(sequence)):  # Minimum loop size of 3\n                if (sequence[i] == 'A' and sequence[j] == 'U') or \\\n                   (sequence[i] == 'U' and sequence[j] == 'A') or \\\n                   (sequence[i] == 'G' and sequence[j] == 'C') or \\\n                   (sequence[i] == 'C' and sequence[j] == 'G'):\n                    # Store the potential base pair\n                    potential_base_pairs.append((i, j))\n        \n        # Randomly select base pairs if we have too many\n        if len(potential_base_pairs) > max_additional_edges // 2:  # Divide by 2 for bidirectional edges\n            # Shuffle and take only what we can handle\n            random.shuffle(potential_base_pairs)\n            potential_base_pairs = potential_base_pairs[:max_additional_edges // 2]\n        \n        # Add the selected base pairs\n        for i, j in potential_base_pairs:\n            edges.append([i, j])\n            edges.append([j, i])  # Bidirectional\n    \n    # Convert edges to tensor\n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    \n    # Get coordinates if available\n    y = None\n    mask = None\n    if labels_df is not None:\n        target_labels = labels_df[labels_df['ID'].str.startswith(target_id + '_')]\n        \n        # Sort by residue ID to match sequence order\n        target_labels = target_labels.sort_values(by='resid')\n        \n        # Check if we have the expected number of residues\n        if len(target_labels) == len(sequence):\n            # Extract coordinates for each residue\n            coordinates = target_labels[['x_1', 'y_1', 'z_1']].values\n            \n            # Create a mask for NaN values (1 for valid, 0 for NaN)\n            valid_mask = ~np.isnan(coordinates).any(axis=1)\n            mask = torch.tensor(valid_mask, dtype=torch.float)\n            \n            # Replace NaN with zeros (we'll mask these during loss calculation)\n            coordinates = np.nan_to_num(coordinates, nan=0.0)\n            \n            y = torch.tensor(coordinates, dtype=torch.float)\n        else:\n            print(f\"Warning: Mismatch in sequence length and label count for {target_id}\")\n    \n    # Create the data object with properly typed target_id (as string)\n    data = Data(x=x, edge_index=edge_index, y=y, mask=mask)\n    \n    # Store target_id as a string attribute\n    data.target_id = str(target_id)\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:18.969899Z","iopub.execute_input":"2025-03-19T21:17:18.970224Z","iopub.status.idle":"2025-03-19T21:17:18.986773Z","shell.execute_reply.started":"2025-03-19T21:17:18.970194Z","shell.execute_reply":"2025-03-19T21:17:18.985799Z"},"papermill":{"duration":0.022807,"end_time":"2025-03-18T21:30:41.762313","exception":false,"start_time":"2025-03-18T21:30:41.739506","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":79},{"id":"c97e40ab","cell_type":"code","source":"def create_dataset(sequences_df, labels_df=None):\n    dataset = []\n    skipped_count = 0\n    nan_count = 0\n    \n    for idx, row in tqdm(sequences_df.iterrows(), total=len(sequences_df)):\n        target_id = row['target_id']\n        sequence = row['sequence']\n        \n        # Clean sequence - replace any non-standard nucleotides with 'N'\n        # and count how many non-standard nucleotides there are\n        cleaned_sequence = ''\n        non_standard_count = 0\n        \n        for nt in sequence:\n            if nt in nucleotide_mapping:\n                cleaned_sequence += nt\n            else:\n                cleaned_sequence += 'N'  # Placeholder for non-standard nucleotides\n                non_standard_count += 1\n        \n        # If too many non-standard nucleotides (>10%), skip this sequence\n        if non_standard_count / len(sequence) > 0.1:\n            print(f\"Skipping sequence {target_id} with {non_standard_count} non-standard nucleotides\")\n            skipped_count += 1\n            continue\n        \n        # Create graph\n        graph = sequence_to_graph(cleaned_sequence, target_id, labels_df)\n        \n        # Check if we have labels with many NaN values\n        if labels_df is not None and hasattr(graph, 'mask') and graph.mask is not None:\n            nan_percentage = 1.0 - torch.mean(graph.mask).item()\n            if nan_percentage > 0.5:  # If more than 50% coordinates are NaN\n                print(f\"Warning: Sequence {target_id} has {nan_percentage:.1%} NaN coordinates\")\n                nan_count += 1\n        \n        # Add to dataset if no labels needed or valid labels exist\n        if labels_df is None or graph.y is not None:\n            dataset.append(graph)\n    \n    print(f\"Dataset creation: {skipped_count} sequences skipped due to non-standard nucleotides\")\n    print(f\"Dataset creation: {nan_count} sequences have >50% NaN coordinates\")\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:18.987872Z","iopub.execute_input":"2025-03-19T21:17:18.988119Z","iopub.status.idle":"2025-03-19T21:17:19.008141Z","shell.execute_reply.started":"2025-03-19T21:17:18.988095Z","shell.execute_reply":"2025-03-19T21:17:19.007241Z"},"papermill":{"duration":0.018896,"end_time":"2025-03-18T21:30:41.790258","exception":false,"start_time":"2025-03-18T21:30:41.771362","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":80},{"id":"588d9533","cell_type":"code","source":"\ndata={\n      \"sequence\":train_sequences['sequence'].to_list(),\n      \"temporal_cutoff\": train_sequences['temporal_cutoff'].to_list(),\n      \"description\": train_sequences['description'].to_list(),\n      \"all_sequences\": train_sequences['all_sequences'].to_list(),\n}\nconfig = {\n    \"cutoff_date\": \"2020-01-01\",\n    \"test_cutoff_date\": \"2022-05-01\",\n}","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:19.011078Z","iopub.execute_input":"2025-03-19T21:17:19.011420Z","iopub.status.idle":"2025-03-19T21:17:19.028182Z","shell.execute_reply.started":"2025-03-19T21:17:19.011395Z","shell.execute_reply":"2025-03-19T21:17:19.027365Z"},"papermill":{"duration":0.019814,"end_time":"2025-03-18T21:30:41.818916","exception":false,"start_time":"2025-03-18T21:30:41.799102","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":81},{"id":"b23b6f8e","cell_type":"code","source":"# Split data into train and test\nall_index = np.arange(len(data['sequence']))\ncutoff_date = pd.Timestamp(config['cutoff_date'])\ntest_cutoff_date = pd.Timestamp(config['test_cutoff_date'])\ntrain_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) <= cutoff_date]\ntest_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) > cutoff_date and pd.Timestamp(d) <= test_cutoff_date]","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:19.030265Z","iopub.execute_input":"2025-03-19T21:17:19.030529Z","iopub.status.idle":"2025-03-19T21:17:19.053225Z","shell.execute_reply.started":"2025-03-19T21:17:19.030508Z","shell.execute_reply":"2025-03-19T21:17:19.052218Z"},"papermill":{"duration":0.018448,"end_time":"2025-03-18T21:30:41.845951","exception":false,"start_time":"2025-03-18T21:30:41.827503","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":82},{"id":"31712e1b","cell_type":"code","source":"# Create training dataset\ntrain_dataset = create_dataset(train_sequences, train_labels)\nprint(f\"Created {len(train_dataset)} graph data objects for training\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:19.054223Z","iopub.execute_input":"2025-03-19T21:17:19.054551Z","iopub.status.idle":"2025-03-19T21:17:51.243229Z","shell.execute_reply.started":"2025-03-19T21:17:19.054517Z","shell.execute_reply":"2025-03-19T21:17:51.242334Z"},"papermill":{"duration":31.631481,"end_time":"2025-03-18T21:31:13.485818","exception":false,"start_time":"2025-03-18T21:30:41.854337","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":" 14%|█▎        | 114/844 [00:04<00:25, 28.13it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1LS2_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 132/844 [00:04<00:25, 27.82it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1P6V_D has 64.7% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 141/844 [00:05<00:25, 27.91it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1QZC_C has 100.0% NaN coordinates\nWarning: Sequence 1R2W_C has 100.0% NaN coordinates\nWarning: Sequence 1QZC_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 147/844 [00:05<00:25, 27.60it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1QZA_B has 100.0% NaN coordinates\nWarning: Sequence 1QZB_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 20%|█▉        | 168/844 [00:06<00:24, 27.51it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1Y1Y_P has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 177/844 [00:06<00:24, 27.49it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1ZC8_Z has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_G has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_J has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_F has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_I has 100.0% NaN coordinates\nWarning: Sequence 1ZC8_H has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 186/844 [00:06<00:23, 27.59it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 1X18_D has 100.0% NaN coordinates\nWarning: Sequence 1X18_A has 100.0% NaN coordinates\nWarning: Sequence 1X18_B has 100.0% NaN coordinates\nWarning: Sequence 1ZN1_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▍       | 207/844 [00:07<00:23, 27.17it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2BS0_S has 55.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 219/844 [00:07<00:23, 26.91it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2AGN_C has 100.0% NaN coordinates\nWarning: Sequence 2AGN_A has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 237/844 [00:08<00:22, 27.01it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2IY3_B has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 246/844 [00:08<00:22, 26.34it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2OB7_D has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 282/844 [00:10<00:20, 27.21it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 2R1G_C has 100.0% NaN coordinates\nWarning: Sequence 2R1G_A has 100.0% NaN coordinates\nWarning: Sequence 2R1G_X has 100.0% NaN coordinates\nWarning: Sequence 2R1G_F has 100.0% NaN coordinates\nWarning: Sequence 2R1G_B has 100.0% NaN coordinates\nWarning: Sequence 2R1G_E has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▋      | 306/844 [00:11<00:19, 27.37it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 3EQ3_E has 100.0% NaN coordinates\nWarning: Sequence 3EQ3_Y has 100.0% NaN coordinates\nWarning: Sequence 3EP2_B has 100.0% NaN coordinates\nWarning: Sequence 3EP2_D has 100.0% NaN coordinates\nWarning: Sequence 3EQ4_A has 100.0% NaN coordinates\nWarning: Sequence 3EP2_C has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 312/844 [00:11<00:19, 27.37it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 3CW1_v has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 348/844 [00:12<00:19, 25.83it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 3PGW_N has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 426/844 [00:15<00:16, 25.79it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BP has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 444/844 [00:16<00:15, 26.05it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BA has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BH has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BL has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▎    | 453/844 [00:17<00:21, 17.94it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BC has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BK has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 459/844 [00:17<00:18, 21.31it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_AH has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BU has 100.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 465/844 [00:17<00:15, 23.94it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 4V5Z_BQ has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_AF has 100.0% NaN coordinates\nWarning: Sequence 4V5Z_BM has 100.0% NaN coordinates\nWarning: Sequence 4OQ9_3 has 90.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 510/844 [00:19<00:12, 27.49it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 5GAP_U has 90.7% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▊   | 579/844 [00:21<00:10, 25.86it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6IV6_G has 55.9% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 594/844 [00:22<00:09, 25.99it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6HYU_D has 66.7% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 615/844 [00:23<00:08, 26.90it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6WB1_C has 68.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▋  | 645/844 [00:24<00:07, 25.87it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6Y0C_IN1 has 59.2% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 675/844 [00:25<00:06, 26.87it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 6WW6_E has 68.5% NaN coordinates\nWarning: Sequence 6WW6_F has 68.5% NaN coordinates\nWarning: Sequence 6WW6_C has 66.7% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 681/844 [00:25<00:06, 26.20it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 7M57_ii has 63.0% NaN coordinates\nWarning: Sequence 7M2T_ss has 74.1% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 693/844 [00:26<00:05, 26.49it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 7SLP_R has 54.3% NaN coordinates\nWarning: Sequence 7S3H_R has 70.6% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 789/844 [00:30<00:02, 25.48it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 8P0B_V has 62.5% NaN coordinates\nWarning: Sequence 8P0G_V has 60.0% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 807/844 [00:30<00:01, 25.20it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 8WT6_E has 67.2% NaN coordinates\nWarning: Sequence 8WT8_F has 62.2% NaN coordinates\nWarning: Sequence 8WT8_E has 67.2% NaN coordinates\nWarning: Sequence 8WT6_F has 62.2% NaN coordinates\nWarning: Sequence 8WT7_E has 67.2% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▋| 813/844 [00:31<00:01, 26.34it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Sequence 8WT7_F has 62.2% NaN coordinates\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 844/844 [00:32<00:00, 26.24it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset creation: 0 sequences skipped due to non-standard nucleotides\nDataset creation: 69 sequences have >50% NaN coordinates\nCreated 844 graph data objects for training\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":83},{"id":"d0c002f1-2273-4250-a4b9-a7ea613b4d48","cell_type":"code","source":"from torch_geometric.data import InMemoryDataset, Data\nimport torch\nimport torch_geometric.transforms as T\n\n\nclass AddGaussianNoise:\n    def __init__(self, std=0.01):\n        self.std = std\n\n    def __call__(self, data):\n        if hasattr(data, 'x') and data.x is not None:\n            noise = torch.randn_like(data.x) * self.std\n            data.x += noise\n        return data\n        \nclass GraphDataset(InMemoryDataset):\n    def __init__(self, data_list, transform=None):\n        super().__init__()\n        self.transform = transform\n        self.data, self.slices = self.collate(data_list)  # Convert list into PyG format\n\n    def get(self, idx):\n        # Retrieve data object by index\n        data = self.data.__class__()\n        for key in self.data.keys():  # ✅ Fix here (use .keys())\n            data[key] = self.data[key][self.slices[key][idx]: self.slices[key][idx + 1]]\n        return data if self.transform is None else self.transform(data)\n\n# ✅ Fix: Pass a list, not a dataset\ntransform = T.Compose([\n    AddGaussianNoise(0.01)  # Keep custom noise\n])\n\ntrain_dataset = GraphDataset(list(train_dataset), transform=transform)\nprint(f\"Dataset converted: {len(train_dataset)} graphs\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:17:51.244325Z","iopub.execute_input":"2025-03-19T21:17:51.244718Z","iopub.status.idle":"2025-03-19T21:17:51.279883Z","shell.execute_reply.started":"2025-03-19T21:17:51.244679Z","shell.execute_reply":"2025-03-19T21:17:51.278904Z"}},"outputs":[{"name":"stdout","text":"Dataset converted: 844 graphs\n","output_type":"stream"}],"execution_count":84},{"id":"1b95b076-927d-48f1-9a77-598cc5b9dc37","cell_type":"code","source":"print(transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:17:51.280863Z","iopub.execute_input":"2025-03-19T21:17:51.281197Z","iopub.status.idle":"2025-03-19T21:17:51.285918Z","shell.execute_reply.started":"2025-03-19T21:17:51.281170Z","shell.execute_reply":"2025-03-19T21:17:51.284968Z"}},"outputs":[{"name":"stdout","text":"Compose([\n  <__main__.AddGaussianNoise object at 0x7f33e16786a0>\n])\n","output_type":"stream"}],"execution_count":85},{"id":"4dc31f8e","cell_type":"code","source":"train_graphs = train_dataset[:len(train_index)]\nval_graphs = train_dataset[:len(train_index)]","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:51.286923Z","iopub.execute_input":"2025-03-19T21:17:51.287158Z","iopub.status.idle":"2025-03-19T21:17:51.304331Z","shell.execute_reply.started":"2025-03-19T21:17:51.287137Z","shell.execute_reply":"2025-03-19T21:17:51.303263Z"},"papermill":{"duration":0.029743,"end_time":"2025-03-18T21:31:13.539686","exception":false,"start_time":"2025-03-18T21:31:13.509943","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":86},{"id":"ec965e1f","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.02554,"end_time":"2025-03-18T21:31:13.589779","exception":false,"start_time":"2025-03-18T21:31:13.564239","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"5e7acbc3","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.02332,"end_time":"2025-03-18T21:31:13.636449","exception":false,"start_time":"2025-03-18T21:31:13.613129","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"2ab88dd4","cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv, BatchNorm\n\nclass RNAStructurePredictor(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, output_dim=3, num_layers=8, max_seq_len=MAX_SEQ_LEN):\n        super(RNAStructurePredictor, self).__init__()\n        \n        # Initial embedding layer\n        self.embedding = nn.Linear(input_dim, hidden_dim)\n\n        # GAT layers with BatchNorm\n        self.conv_layers = nn.ModuleList()\n        self.norm_layers = nn.ModuleList()\n        for _ in range(num_layers):\n            self.conv_layers.append(GATConv(hidden_dim, hidden_dim, heads=4, concat=False))\n            self.norm_layers.append(BatchNorm(hidden_dim))\n\n        # Output layer\n        self.output = nn.Linear(hidden_dim, output_dim)\n\n        # Position encoding\n        self.position_encoder = nn.Embedding(max_seq_len, hidden_dim)\n\n        # Xavier Initialization\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n\n        # Embedding\n        x = self.embedding(x)\n        max_pos = self.position_encoder.weight.size(0) - 1\n        pos = torch.clamp(torch.arange(x.size(0), device=x.device), max=max_pos)\n        x = x + self.position_encoder(pos)\n\n        # Graph convolution layers\n        for conv, norm in zip(self.conv_layers, self.norm_layers):\n            x = F.relu(conv(x, edge_index))\n            x = norm(x)\n            x = F.dropout(x, p=0.2, training=self.training)\n\n        # Predict coordinates\n        return self.output(x)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:03.895780Z","iopub.execute_input":"2025-03-19T21:18:03.896138Z","iopub.status.idle":"2025-03-19T21:18:03.905915Z","shell.execute_reply.started":"2025-03-19T21:18:03.896112Z","shell.execute_reply":"2025-03-19T21:18:03.904843Z"},"papermill":{"duration":0.033484,"end_time":"2025-03-18T21:31:13.693362","exception":false,"start_time":"2025-03-18T21:31:13.659878","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":100},{"id":"6f843a4f","cell_type":"code","source":"# Define loss function for 3D coordinate prediction\ndef rmsd_loss(pred, target, mask=None):\n    \"\"\"\n    Root Mean Square Deviation (RMSD) loss function with optional masking for NaN values.\n    Lower RMSD indicates better structural similarity.\n    \n    Args:\n        pred: Predicted coordinates, shape (n_nucleotides, 3)\n        target: Target coordinates, shape (n_nucleotides, 3)\n        mask: Optional mask for valid values, shape (n_nucleotides,)\n    \"\"\"\n    squared_diff = torch.sum((pred - target) ** 2, dim=1)\n    \n    if mask is not None:\n        # Apply mask to consider only valid coordinates\n        # Ensure we don't divide by zero by adding a small epsilon to the sum\n        masked_squared_diff = squared_diff * mask\n        mean_squared_diff = torch.sum(masked_squared_diff) / (torch.sum(mask) + 1e-10)\n    else:\n        mean_squared_diff = torch.mean(squared_diff)\n    \n    rmsd = torch.sqrt(mean_squared_diff)\n    return rmsd","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:07.183154Z","iopub.execute_input":"2025-03-19T21:18:07.183542Z","iopub.status.idle":"2025-03-19T21:18:07.189093Z","shell.execute_reply.started":"2025-03-19T21:18:07.183511Z","shell.execute_reply":"2025-03-19T21:18:07.187924Z"},"papermill":{"duration":0.030514,"end_time":"2025-03-18T21:31:13.747121","exception":false,"start_time":"2025-03-18T21:31:13.716607","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":101},{"id":"5a2e3933","cell_type":"code","source":"def calculate_distance_matrix(X,Y,epsilon=1e-4):\n    return (torch.square(X[:,None]-Y[None,:])+epsilon).sum(-1).sqrt()\n\n\ndef dRMSD(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=None):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=~torch.isnan(gt_dm)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n    if d_clamp is not None:\n        rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).clip(0,d_clamp**2)\n    else:\n        rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n\n    return rmsd.sqrt().mean()/Z\n\ndef local_dRMSD(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=30):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=(~torch.isnan(gt_dm))*(gt_dm<d_clamp)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n\n\n    rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n    # rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).sqrt()/Z\n    #rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])/Z\n    return rmsd.sqrt().mean()/Z\n\ndef dRMAE(pred_x,\n          pred_y,\n          gt_x,\n          gt_y,\n          epsilon=1e-4,Z=10,d_clamp=None):\n    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n\n\n\n    mask=~torch.isnan(gt_dm)\n    mask[torch.eye(mask.shape[0]).bool()]=False\n\n    rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])\n\n    return rmsd.mean()/Z\n\nimport torch\n\ndef align_svd_mae(input, target, Z=10):\n    \"\"\"\n    Aligns the input (Nx3) to target (Nx3) using SVD-based Procrustes alignment\n    and computes RMSD loss.\n    \n    Args:\n        input (torch.Tensor): Nx3 tensor representing the input points.\n        target (torch.Tensor): Nx3 tensor representing the target points.\n    \n    Returns:\n        aligned_input (torch.Tensor): Nx3 aligned input.\n        rmsd_loss (torch.Tensor): RMSD loss.\n    \"\"\"\n    assert input.shape == target.shape, \"Input and target must have the same shape\"\n\n    #mask \n    mask=~torch.isnan(target.sum(-1))\n\n    input=input[mask]\n    target=target[mask]\n    \n    # Compute centroids\n    centroid_input = input.mean(dim=0, keepdim=True)\n    centroid_target = target.mean(dim=0, keepdim=True)\n\n    # Center the points\n    input_centered = input - centroid_input.detach()\n    target_centered = target - centroid_target\n\n    # Compute covariance matrix\n    cov_matrix = input_centered.T @ target_centered\n\n    # SVD to find optimal rotation\n    U, S, Vt = torch.svd(cov_matrix)\n\n    # Compute rotation matrix\n    R = Vt @ U.T\n\n    # Ensure a proper rotation (det(R) = 1, no reflection)\n    if torch.det(R) < 0:\n        Vt[-1, :] *= -1\n        R = Vt @ U.T\n\n    # Rotate input\n    aligned_input = (input_centered @ R.T.detach()) + centroid_target.detach()\n\n    # # Compute RMSD loss\n    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n\n    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n    \n    # return aligned_input, rmsd_loss\n    return torch.abs(aligned_input-target).mean()/Z","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:09.538172Z","iopub.execute_input":"2025-03-19T21:18:09.538495Z","iopub.status.idle":"2025-03-19T21:18:09.552414Z","shell.execute_reply.started":"2025-03-19T21:18:09.538459Z","shell.execute_reply":"2025-03-19T21:18:09.551512Z"},"papermill":{"duration":0.038356,"end_time":"2025-03-18T21:31:13.809058","exception":false,"start_time":"2025-03-18T21:31:13.770702","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":102},{"id":"d5c54ec1-f67a-4c4b-8362-94e3788e7fcc","cell_type":"code","source":"criterion = nn.SmoothL1Loss(beta=0.1)  # Huber Loss (more robust than MSE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:18:13.311669Z","iopub.execute_input":"2025-03-19T21:18:13.312047Z","iopub.status.idle":"2025-03-19T21:18:13.316771Z","shell.execute_reply.started":"2025-03-19T21:18:13.312015Z","shell.execute_reply":"2025-03-19T21:18:13.315799Z"}},"outputs":[],"execution_count":103},{"id":"eeb9da52","cell_type":"code","source":"import torch\nimport numpy as np\nfrom tqdm import tqdm\n\ndef train(model, train_loader, optimizer, device):\n    model.train()\n    total_loss = 0\n    loss_values = []\n    scaler = torch.cuda.amp.GradScaler()  # Enable mixed precision training\n    \n    pbar = tqdm(train_loader, desc='Training')\n    \n    for data in pbar:\n        data = data.to(device)\n        optimizer.zero_grad()\n        \n        with torch.autocast(device_type='cuda', dtype=torch.float16):  # Use FP16 where possible\n            pred = model(data)\n            \n            if data.y is not None:\n                if hasattr(data, 'mask') and data.mask is not None:\n                    loss = dRMAE(pred, pred, data.y, data.y) + align_svd_mae(pred, data.y)\n                else:\n                    loss = dRMAE(pred, pred, data.y, data.y) + align_svd_mae(pred, data.y)\n        \n        # Backward pass with AMP\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item()\n        loss_values.append(loss.item())\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'smooth loss': np.mean(loss_values[-100:])})\n\n    avg_loss = total_loss / len(train_loader)\n    return avg_loss\n\ndef validate(model, val_loader, device):\n    model.eval()\n    total_loss = 0\n    \n    pbar = tqdm(val_loader, desc='Validation')\n    \n    with torch.no_grad():\n        for data in pbar:\n            data = data.to(device)\n            pred = model(data)\n            \n            if data.y is not None:\n                if hasattr(data, 'mask') and data.mask is not None:\n                    loss = dRMAE(pred, pred, data.y, data.y) + align_svd_mae(pred, data.y)\n                else:\n                    loss = dRMAE(pred, pred, data.y, data.y) + align_svd_mae(pred, data.y)\n\n                total_loss += loss.item()\n                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n    avg_loss = total_loss / len(val_loader)\n    return avg_loss\n","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:13.799266Z","iopub.execute_input":"2025-03-19T21:18:13.799628Z","iopub.status.idle":"2025-03-19T21:18:13.809482Z","shell.execute_reply.started":"2025-03-19T21:18:13.799597Z","shell.execute_reply":"2025-03-19T21:18:13.808421Z"},"papermill":{"duration":0.034959,"end_time":"2025-03-18T21:31:13.867481","exception":false,"start_time":"2025-03-18T21:31:13.832522","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":104},{"id":"d298df36","cell_type":"code","source":"# Function to make predictions on test data\ndef predict(model, test_loader, device):\n    model.eval()\n    predictions = {}\n    \n    with torch.no_grad():\n        for data in test_loader:\n            data = data.to(device)\n            pred = model(data)\n            \n            # Store predictions\n            target_id = data.target_id\n            \n            # If we have ground truth and mask, report metrics\n            if hasattr(data, 'y') and data.y is not None:\n                if hasattr(data, 'mask') and data.mask is not None:\n                    loss = rmsd_loss(pred, data.y, data.mask).item()\n                else:\n                    loss = rmsd_loss(pred, data.y).item()\n                print(f\"Prediction for {target_id}, RMSD: {loss:.4f}\")\n            \n            predictions[target_id] = pred.cpu().numpy()\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:16.707519Z","iopub.execute_input":"2025-03-19T21:18:16.707883Z","iopub.status.idle":"2025-03-19T21:18:16.713897Z","shell.execute_reply.started":"2025-03-19T21:18:16.707822Z","shell.execute_reply":"2025-03-19T21:18:16.712946Z"},"papermill":{"duration":0.032272,"end_time":"2025-03-18T21:31:13.923883","exception":false,"start_time":"2025-03-18T21:31:13.891611","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":105},{"id":"661f46a8","cell_type":"code","source":"# Setup for training\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = 'cuda'\nelif torch.backends.mps.is_available():\n    device = 'mps'\ndevice = torch.device(device)\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:17.929094Z","iopub.execute_input":"2025-03-19T21:18:17.929414Z","iopub.status.idle":"2025-03-19T21:18:17.935220Z","shell.execute_reply.started":"2025-03-19T21:18:17.929390Z","shell.execute_reply":"2025-03-19T21:18:17.934281Z"},"papermill":{"duration":0.032031,"end_time":"2025-03-18T21:31:13.980191","exception":false,"start_time":"2025-03-18T21:31:13.948160","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":106},{"id":"72a96a27","cell_type":"code","source":"# Create data loaders\ntrain_loader = DataLoader(train_graphs, batch_size=8, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_graphs, batch_size=8, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:18.976308Z","iopub.execute_input":"2025-03-19T21:18:18.976651Z","iopub.status.idle":"2025-03-19T21:18:18.981424Z","shell.execute_reply.started":"2025-03-19T21:18:18.976626Z","shell.execute_reply":"2025-03-19T21:18:18.980270Z"},"papermill":{"duration":0.029999,"end_time":"2025-03-18T21:31:14.033244","exception":false,"start_time":"2025-03-18T21:31:14.003245","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":107},{"id":"dfbda659","cell_type":"code","source":"# Initialize model\ninput_dim = 4  # One-hot encoding dimension for nucleotides\nmodel = RNAStructurePredictor(input_dim, hidden_dim=1024, output_dim=3, num_layers=15, max_seq_len=10000).to(device)\nprint(f\"Model initialized with max sequence length of 10000\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:19.996275Z","iopub.execute_input":"2025-03-19T21:18:19.996595Z","iopub.status.idle":"2025-03-19T21:18:21.229792Z","shell.execute_reply.started":"2025-03-19T21:18:19.996570Z","shell.execute_reply":"2025-03-19T21:18:21.228811Z"},"papermill":{"duration":0.939162,"end_time":"2025-03-18T21:31:14.995512","exception":false,"start_time":"2025-03-18T21:31:14.056350","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Model initialized with max sequence length of 10000\n","output_type":"stream"}],"execution_count":108},{"id":"640ee8e4-8868-4993-9b9d-f21bcf37e131","cell_type":"code","source":"# from torch.optim import Optimizer\n\n# class Lookahead(Optimizer):\n#     \"\"\"Lookahead Optimizer Wrapper\"\"\"\n\n#     def __init__(self, base_optimizer, k=5, alpha=0.5):\n#         if not 0.0 <= alpha <= 1.0:\n#             raise ValueError(\"alpha must be in [0, 1]\")\n#         if not k >= 1:\n#             raise ValueError(\"k must be at least 1\")\n        \n#         self.base_optimizer = base_optimizer\n#         self.k = k\n#         self.alpha = alpha\n#         self.param_groups = self.base_optimizer.param_groups  # Expose param_groups\n\n#         # Backup parameters\n#         self.slow_weights = [param.clone().detach() for group in self.param_groups for param in group[\"params\"]]\n#         for w in self.slow_weights:\n#             w.requires_grad = False\n#         self.counter = 0\n\n#     def step(self, closure=None):\n#         loss = self.base_optimizer.step(closure)\n#         self.counter += 1\n\n#         if self.counter >= self.k:\n#             self.counter = 0\n#             for group, slow_weight in zip(self.param_groups, self.slow_weights):\n#                 for param, slow_param in zip(group[\"params\"], slow_weight):\n#                     slow_param.add_(self.alpha * (param - slow_param))\n#                     param.data.copy_(slow_param)\n\n#         return loss\n\n#     def zero_grad(self, set_to_none=False):\n#         self.base_optimizer.zero_grad(set_to_none=set_to_none)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:18:22.139357Z","iopub.execute_input":"2025-03-19T21:18:22.139750Z","iopub.status.idle":"2025-03-19T21:18:22.143743Z","shell.execute_reply.started":"2025-03-19T21:18:22.139717Z","shell.execute_reply":"2025-03-19T21:18:22.142887Z"}},"outputs":[],"execution_count":109},{"id":"b167ccbc","cell_type":"code","source":"from torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.optim import AdamW\nfrom timm.optim.lookahead import Lookahead\n\n\nbase_optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\noptimizer = Lookahead(base_optimizer, k=5, alpha=0.5)  # Use Lookahead wrapper\n\n# Use base_optimizer for the scheduler to avoid issues\nscheduler = CosineAnnealingLR(base_optimizer, T_max=50)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:23.577488Z","iopub.execute_input":"2025-03-19T21:18:23.577812Z","iopub.status.idle":"2025-03-19T21:18:23.583806Z","shell.execute_reply.started":"2025-03-19T21:18:23.577787Z","shell.execute_reply":"2025-03-19T21:18:23.582853Z"},"papermill":{"duration":0.029976,"end_time":"2025-03-18T21:31:15.049722","exception":false,"start_time":"2025-03-18T21:31:15.019746","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":110},{"id":"452fbfa5-027a-40d9-8208-76b76cedabb3","cell_type":"code","source":"print(hasattr(optimizer, 'defaults'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:18:24.800474Z","iopub.execute_input":"2025-03-19T21:18:24.800860Z","iopub.status.idle":"2025-03-19T21:18:24.805776Z","shell.execute_reply.started":"2025-03-19T21:18:24.800806Z","shell.execute_reply":"2025-03-19T21:18:24.804782Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":111},{"id":"f3519dc1-484e-4442-9c37-f8c6f7e9d2da","cell_type":"code","source":"import torch\nfrom torch_geometric.data import Data\n\n# Assuming 'sequence' represents node features\nnode_features = torch.tensor(data[\"sequence\"], dtype=torch.float32)  # Ensure correct dtype\nedge_index = torch.tensor(data[\"edge_index\"], dtype=torch.long)  # Ensure correct dtype\nlabels = torch.tensor(data[\"labels\"], dtype=torch.float32)  # If available\n\n# Create a PyG Data object\ngraph_data = Data(\n    x=node_features,\n    edge_index=edge_index,\n    y=labels\n)\n\nprint(graph_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:22:47.085323Z","iopub.execute_input":"2025-03-19T21:22:47.085689Z","iopub.status.idle":"2025-03-19T21:22:47.113917Z","shell.execute_reply.started":"2025-03-19T21:22:47.085660Z","shell.execute_reply":"2025-03-19T21:22:47.112205Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-767fbac2cb87>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming 'sequence' represents node features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnode_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure correct dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"edge_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure correct dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# If available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"],"ename":"ValueError","evalue":"too many dimensions 'str'","output_type":"error"}],"execution_count":118},{"id":"0f391717-367d-4301-93a9-cefdb284f215","cell_type":"code","source":"print(data.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T21:21:08.713257Z","iopub.execute_input":"2025-03-19T21:21:08.713674Z","iopub.status.idle":"2025-03-19T21:21:08.719562Z","shell.execute_reply.started":"2025-03-19T21:21:08.713645Z","shell.execute_reply":"2025-03-19T21:21:08.718227Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['sequence', 'temporal_cutoff', 'description', 'all_sequences'])\n","output_type":"stream"}],"execution_count":116},{"id":"5a7593f5-222d-4775-890b-464a093a2de3","cell_type":"markdown","source":"","metadata":{}},{"id":"a939e1fa","cell_type":"code","source":"# Training loop\nnum_epochs = 2000\nbest_val_loss = float('inf')\nearly_stopping_patience = 150\nearly_stopping_counter = 0\n\ntrain_losses = []\nval_losses = []\n\nprint(\"Starting training...\")\nfor epoch in range(num_epochs):\n    # Train\n    train_loss = train(model, train_loader, optimizer, device)\n    train_losses.append(train_loss)\n    \n    # Validate\n    val_loss = validate(model, val_loader, device)\n    val_losses.append(val_loss)\n    \n    # Learning rate scheduler\n    scheduler.step(val_loss)\n    \n    # Early stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        early_stopping_counter = 0\n        # Save best model\n        torch.save(model.state_dict(), \"best_rna_structure_model.pt\")\n    else:\n        early_stopping_counter += 1\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Train Loss: {train_loss:.4f}, \"\n          f\"Val Loss: {val_loss:.4f}, \"\n          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n    \n    if early_stopping_counter >= early_stopping_patience:\n        print(f\"Early stopping triggered after {epoch+1} epochs\")\n        break\n\nprint(\"Training completed!\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:18:25.978441Z","iopub.execute_input":"2025-03-19T21:18:25.978859Z","iopub.status.idle":"2025-03-19T21:18:26.236614Z","shell.execute_reply.started":"2025-03-19T21:18:25.978815Z","shell.execute_reply":"2025-03-19T21:18:26.235243Z"},"papermill":{"duration":1645.196381,"end_time":"2025-03-18T21:58:40.269986","exception":false,"start_time":"2025-03-18T21:31:15.073605","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-104-c8b06097a999>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()  # Enable mixed precision training\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/76 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n  warnings.warn(msg)\n/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n  warnings.warn(msg)\n/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n  warnings.warn(msg)\n/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n  warnings.warn(msg)\nTraining:   0%|          | 0/76 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-112-71b60208534b>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-104-c8b06097a999>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Use FP16 where possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-100-13a51f7a1fd7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Graph convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 edge_index, edge_attr = remove_self_loops(\n\u001b[0m\u001b[1;32m    348\u001b[0m                     edge_index, edge_attr)\n\u001b[1;32m    349\u001b[0m                 edge_index, edge_attr = add_self_loops(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36mremove_self_loops\u001b[0;34m(edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mis_undirected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_undirected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"],"ename":"IndexError","evalue":"index 0 is out of bounds for dimension 0 with size 0","output_type":"error"}],"execution_count":112},{"id":"6d1947fc","cell_type":"code","source":"# Plot training and validation losses\nplt.figure(figsize=(10, 6))\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('RMSD Loss')\nplt.title('Training and Validation Losses')\nplt.legend()\nplt.grid(True)\nplt.savefig('training_loss.png')\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:52.996399Z","iopub.status.idle":"2025-03-19T21:17:52.996721Z","shell.execute_reply":"2025-03-19T21:17:52.996594Z"},"papermill":{"duration":2.05675,"end_time":"2025-03-18T21:58:44.073095","exception":false,"start_time":"2025-03-18T21:58:42.016345","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7acecbda","cell_type":"code","source":"# Generate multiple conformations for each RNA sequence\ndef generate_multiple_conformations(model, data, num_conformations=5):\n    \"\"\"\n    Generate multiple structural conformations for an RNA sequence.\n    \n    Args:\n        model: The trained GNN model\n        data: Graph data object containing the RNA sequence\n        num_conformations: Number of conformations to generate (default: 5)\n        \n    Returns:\n        List of numpy arrays, each array has shape (n_nucleotides, 3) for x,y,z coordinates\n    \"\"\"\n    model.eval()\n    conformations = []\n    \n    # Set random seed for reproducibility\n    torch.manual_seed(42)\n    \n    with torch.no_grad():\n        # Generate first conformation (deterministic)\n        base_pred = model(data)\n        base_np = base_pred.cpu().numpy()\n        \n        # Check if base prediction contains NaN values\n        if np.isnan(base_np).any():\n            print(\"Warning: Base prediction contains NaN values. Replacing with zeros.\")\n            base_np = np.nan_to_num(base_np, nan=0.0)\n        \n        # Save the base prediction\n        conformations.append(base_np)\n        \n        # Generate additional conformations with controlled variations\n        for i in range(1, num_conformations):\n            # Use different seeds for different conformations\n            torch.manual_seed(42 + i * 100)  # Larger seed increment for more diversity\n            \n            # Create a copy of the base prediction with a small, controlled variation\n            variation = base_np.copy()\n            \n            # Add random noise with small magnitude (1-5% of the coordinate values)\n            # Calculate standard deviation of base coordinates to scale noise appropriately\n            if not np.all(base_np == 0):  # Check if base_np is not all zeros\n                coord_std = max(np.std(base_np), 0.5)  # Use at least 0.5 to avoid too small noise\n                noise_scale = coord_std * 0.05 * (i + 1)  # Increasing noise for each conformation\n            else:\n                # If base prediction is all zeros (which shouldn't happen normally)\n                noise_scale = 0.5 * (i + 1)\n            \n            # Generate noise and ensure it's not NaN\n            noise = np.random.normal(0, noise_scale, size=variation.shape)\n            \n            # Apply noise to create a new conformation\n            variation += noise\n            \n            # Ensure no NaN values\n            variation = np.nan_to_num(variation, nan=0.0)\n            \n            conformations.append(variation)\n    \n    # Double-check that all conformations are valid and contain no NaNs\n    for i, conf in enumerate(conformations):\n        if np.isnan(conf).any():\n            print(f\"Warning: Conformation {i+1} contains NaN values after processing. Replacing with zeros.\")\n            conformations[i] = np.nan_to_num(conf, nan=0.0)\n    \n    return conformations\n\n# Function to make multiple predictions for test data\ndef predict_multiple_conformations(model, test_loader, device, num_conformations=5):\n    predictions = {}\n    \n    for data in test_loader:\n        data = data.to(device)\n        conformations = generate_multiple_conformations(model, data, num_conformations)\n        \n        # Store predictions - ensure target_id is a hashable type (string)\n        # The target_id could be stored as a list or other non-hashable type\n        if hasattr(data, 'target_id'):\n            # Convert to string if it's not already\n            if isinstance(data.target_id, list) and len(data.target_id) > 0:\n                target_id = str(data.target_id[0])  # Take the first element if it's a list\n            else:\n                target_id = str(data.target_id)  # Convert to string to ensure hashability\n        else:\n            # Generate a unique ID if none exists\n            target_id = f\"unknown_target_{len(predictions)}\"\n            \n        print(f\"Processing target: {target_id}\")\n        predictions[target_id] = conformations\n        \n        # If we have ground truth, report metrics for the first conformation\n        if hasattr(data, 'y') and data.y is not None and len(conformations) > 0:\n            first_conf = torch.tensor(conformations[0], device=device)\n            \n            if hasattr(data, 'mask') and data.mask is not None:\n                loss = rmsd_loss(first_conf, data.y, data.mask).item()\n            else:\n                loss = rmsd_loss(first_conf, data.y).item()\n                \n            print(f\"Prediction for {target_id}, RMSD of first conformation: {loss:.4f}\")\n    \n    return predictions\n\n# Example of how to use the prediction function on test data\ndef process_test_data(test_sequences_path):\n    # Load test sequences\n    test_sequences = pd.read_csv(test_sequences_path)\n    \n    # Create test dataset (without labels)\n    test_dataset = create_dataset(test_sequences)\n    \n    # Create test loader\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n    \n    # Make predictions\n    predictions = predict_multiple_conformations(model, test_loader, device)\n    \n    # Format predictions for submission\n    formatted_predictions = []\n    \n    for target_id, conformations in predictions.items():\n        for i, conformation in enumerate(conformations):\n            for j, coords in enumerate(conformation):\n                resid = j + 1  # 1-based indexing\n                row = {\n                    'ID': f\"{target_id}_{resid}\",\n                    f'x_{i+1}': coords[0],\n                    f'y_{i+1}': coords[1],\n                    f'z_{i+1}': coords[2]\n                }\n                formatted_predictions.append(row)\n    \n    # Create submission dataframe\n    submission_df = pd.DataFrame(formatted_predictions)\n    return submission_df","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:52.997883Z","iopub.status.idle":"2025-03-19T21:17:52.998231Z","shell.execute_reply":"2025-03-19T21:17:52.998099Z"},"papermill":{"duration":1.728068,"end_time":"2025-03-18T21:58:47.490327","exception":false,"start_time":"2025-03-18T21:58:45.762259","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"45124c12","cell_type":"code","source":"test_predictions = process_test_data(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")\nsub = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/sample_submission.csv\")\nDF_ROWS = []\n\nfor i, row in sub.iterrows():\n    snap = test_predictions[test_predictions['ID'] == row['ID']]\n    x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5 = snap['x_1'], snap['y_1'], snap['z_1'], snap['x_2'], snap['y_2'], snap['z_2'], snap['x_3'], snap['y_3'], snap['z_3'], snap['x_4'], snap['y_4'], snap['z_4'], snap['x_5'], snap['y_5'], snap['z_5']\n    x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5 = x1.values[0], y1.values[0], z1.values[0], x2.values[1], y2.values[1], z2.values[1], x3.values[2], y3.values[2], z3.values[2], x4.values[3], y4.values[3], z4.values[3], x5.values[4], y5.values[4], z5.values[4]\n    _row = [x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5]\n    DF_ROWS.append(_row)\nsub[['x_1', 'y_1', 'z_1', 'x_2', 'y_2', 'z_2', 'x_3', 'y_3', 'z_3', 'x_4', 'y_4', 'z_4', 'x_5', 'y_5', 'z_5']] = DF_ROWS\nsub.head()\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T21:17:52.999454Z","iopub.status.idle":"2025-03-19T21:17:52.999749Z","shell.execute_reply":"2025-03-19T21:17:52.999630Z"},"papermill":{"duration":7.152758,"end_time":"2025-03-18T21:58:56.430101","exception":false,"start_time":"2025-03-18T21:58:49.277343","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"740beebb","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.770121,"end_time":"2025-03-18T21:59:00.008221","exception":false,"start_time":"2025-03-18T21:58:58.238100","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"ab071188","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.829991,"end_time":"2025-03-18T21:59:03.563919","exception":false,"start_time":"2025-03-18T21:59:01.733928","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7b4295fe","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.751486,"end_time":"2025-03-18T21:59:07.065857","exception":false,"start_time":"2025-03-18T21:59:05.314371","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c236fdf7","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.757,"end_time":"2025-03-18T21:59:10.548249","exception":false,"start_time":"2025-03-18T21:59:08.791249","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a89dd225","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.708894,"end_time":"2025-03-18T21:59:14.078729","exception":false,"start_time":"2025-03-18T21:59:12.369835","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"ee40f10f","cell_type":"code","source":"","metadata":{"papermill":{"duration":1.724742,"end_time":"2025-03-18T21:59:17.541706","exception":false,"start_time":"2025-03-18T21:59:15.816964","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}