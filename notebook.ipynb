{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb860014",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:16.745614Z",
     "iopub.status.busy": "2025-03-18T21:30:16.745302Z",
     "iopub.status.idle": "2025-03-18T21:30:39.471000Z",
     "shell.execute_reply": "2025-03-18T21:30:39.469803Z"
    },
    "papermill": {
     "duration": 22.7356,
     "end_time": "2025-03-18T21:30:39.472849",
     "exception": false,
     "start_time": "2025-03-18T21:30:16.737249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\r\n",
      "Collecting pyg_lib\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/pyg_lib-0.4.0%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_scatter\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_sparse\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_cluster\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch_spline_conv\r\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\r\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\r\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\r\n",
      "Successfully installed pyg_lib-0.4.0+pt21cu121 torch_cluster-1.6.3+pt21cu121 torch_scatter-2.1.2+pt21cu121 torch_sparse-0.6.18+pt21cu121 torch_spline_conv-1.2.2+pt21cu121\r\n",
      "Collecting torch_geometric\r\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\r\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\r\n",
      "Successfully installed torch_geometric-2.6.1\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/libpyg.so: undefined symbol: _ZN2at4_ops10zeros_like4callERKNS_6TensorEN3c108optionalINS5_10ScalarTypeEEENS6_INS5_6LayoutEEENS6_INS5_6DeviceEEENS6_IbEENS6_INS5_12MemoryFormatEEE\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! PyG version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "# First install CUDA-compatible dependencies\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "\n",
    "# Then install torch-geometric\n",
    "!pip install torch_geometric \n",
    "\n",
    "# Verify installation\n",
    "import torch_geometric\n",
    "print(f\"Success! PyG version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08083c5a",
   "metadata": {
    "papermill": {
     "duration": 0.008448,
     "end_time": "2025-03-18T21:30:39.491034",
     "exception": false,
     "start_time": "2025-03-18T21:30:39.482586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6360cfcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:39.508844Z",
     "iopub.status.busy": "2025-03-18T21:30:39.508334Z",
     "iopub.status.idle": "2025-03-18T21:30:41.293433Z",
     "shell.execute_reply": "2025-03-18T21:30:41.292722Z"
    },
    "papermill": {
     "duration": 1.795738,
     "end_time": "2025-03-18T21:30:41.295192",
     "exception": false,
     "start_time": "2025-03-18T21:30:39.499454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23a90bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.313801Z",
     "iopub.status.busy": "2025-03-18T21:30:41.313188Z",
     "iopub.status.idle": "2025-03-18T21:30:41.317280Z",
     "shell.execute_reply": "2025-03-18T21:30:41.316463Z"
    },
    "papermill": {
     "duration": 0.014465,
     "end_time": "2025-03-18T21:30:41.318583",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.304118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b35ccc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.335421Z",
     "iopub.status.busy": "2025-03-18T21:30:41.335171Z",
     "iopub.status.idle": "2025-03-18T21:30:41.679295Z",
     "shell.execute_reply": "2025-03-18T21:30:41.678129Z"
    },
    "papermill": {
     "duration": 0.354536,
     "end_time": "2025-03-18T21:30:41.681259",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.326723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 844 RNA sequences and 137095 nucleotide labels\n"
     ]
    }
   ],
   "source": [
    "# Define paths to data files\n",
    "TRAIN_SEQUENCES_PATH = \"/kaggle/input/stanford-rna-3d-folding/train_sequences.csv\"\n",
    "TRAIN_LABELS_PATH = \"/kaggle/input/stanford-rna-3d-folding/train_labels.csv\"\n",
    "# Load data\n",
    "train_sequences = pd.read_csv(TRAIN_SEQUENCES_PATH)\n",
    "train_labels = pd.read_csv(TRAIN_LABELS_PATH)\n",
    "\n",
    "print(f\"Loaded {len(train_sequences)} RNA sequences and {len(train_labels)} nucleotide labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac513a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.700118Z",
     "iopub.status.busy": "2025-03-18T21:30:41.699783Z",
     "iopub.status.idle": "2025-03-18T21:30:41.704093Z",
     "shell.execute_reply": "2025-03-18T21:30:41.703073Z"
    },
    "papermill": {
     "duration": 0.015698,
     "end_time": "2025-03-18T21:30:41.705752",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.690054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# 1. Encoding nucleotides\n",
    "nucleotide_mapping = {'A': 0, 'C': 1, 'G': 2, 'U': 3}\n",
    "reverse_mapping = {0: 'A', 1: 'C', 2: 'G', 3: 'U'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2159680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.724453Z",
     "iopub.status.busy": "2025-03-18T21:30:41.724130Z",
     "iopub.status.idle": "2025-03-18T21:30:41.728924Z",
     "shell.execute_reply": "2025-03-18T21:30:41.727903Z"
    },
    "papermill": {
     "duration": 0.015969,
     "end_time": "2025-03-18T21:30:41.730544",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.714575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Create feature representation for each nucleotide\n",
    "def one_hot_encode(nucleotide):\n",
    "    encoding = [0, 0, 0, 0]\n",
    "    if nucleotide in nucleotide_mapping:\n",
    "        encoding[nucleotide_mapping[nucleotide]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6590b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.749834Z",
     "iopub.status.busy": "2025-03-18T21:30:41.749462Z",
     "iopub.status.idle": "2025-03-18T21:30:41.760681Z",
     "shell.execute_reply": "2025-03-18T21:30:41.759541Z"
    },
    "papermill": {
     "duration": 0.022807,
     "end_time": "2025-03-18T21:30:41.762313",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.739506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create a graph from an RNA sequence\n",
    "def sequence_to_graph(sequence, target_id, labels_df=None, max_connections=MAX_SEQ_LEN):\n",
    "    \"\"\"\n",
    "    Create a graph representation of an RNA sequence.\n",
    "    \n",
    "    Args:\n",
    "        sequence: The RNA sequence\n",
    "        target_id: Identifier for the RNA\n",
    "        labels_df: Optional dataframe with 3D coordinate labels\n",
    "        max_connections: Maximum number of edges to create (to avoid CUDA OOM errors)\n",
    "        \n",
    "    Returns:\n",
    "        PyTorch Geometric Data object\n",
    "    \"\"\"\n",
    "    # One-hot encode each nucleotide\n",
    "    x = [one_hot_encode(nt) for nt in sequence]\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    \n",
    "    # Create edges - connect adjacent nucleotides (backbone)\n",
    "    # and potentially other connections based on domain knowledge\n",
    "    edges = []\n",
    "    \n",
    "    # Always add backbone connections\n",
    "    for i in range(len(sequence) - 1):\n",
    "        # Connect to next nucleotide (backbone)\n",
    "        edges.append([i, i + 1])\n",
    "        edges.append([i + 1, i])  # Bidirectional\n",
    "    \n",
    "    # Add potential base-pairing connections, but limit total edges to avoid OOM\n",
    "    edge_count = len(edges)\n",
    "    max_additional_edges = max_connections - edge_count\n",
    "    \n",
    "    if max_additional_edges > 0:\n",
    "        potential_base_pairs = []\n",
    "        \n",
    "        # Identify potential base pairs (A-U, G-C)\n",
    "        for i in range(len(sequence)):\n",
    "            for j in range(i + 3, len(sequence)):  # Minimum loop size of 3\n",
    "                if (sequence[i] == 'A' and sequence[j] == 'U') or \\\n",
    "                   (sequence[i] == 'U' and sequence[j] == 'A') or \\\n",
    "                   (sequence[i] == 'G' and sequence[j] == 'C') or \\\n",
    "                   (sequence[i] == 'C' and sequence[j] == 'G'):\n",
    "                    # Store the potential base pair\n",
    "                    potential_base_pairs.append((i, j))\n",
    "        \n",
    "        # Randomly select base pairs if we have too many\n",
    "        if len(potential_base_pairs) > max_additional_edges // 2:  # Divide by 2 for bidirectional edges\n",
    "            # Shuffle and take only what we can handle\n",
    "            random.shuffle(potential_base_pairs)\n",
    "            potential_base_pairs = potential_base_pairs[:max_additional_edges // 2]\n",
    "        \n",
    "        # Add the selected base pairs\n",
    "        for i, j in potential_base_pairs:\n",
    "            edges.append([i, j])\n",
    "            edges.append([j, i])  # Bidirectional\n",
    "    \n",
    "    # Convert edges to tensor\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Get coordinates if available\n",
    "    y = None\n",
    "    mask = None\n",
    "    if labels_df is not None:\n",
    "        target_labels = labels_df[labels_df['ID'].str.startswith(target_id + '_')]\n",
    "        \n",
    "        # Sort by residue ID to match sequence order\n",
    "        target_labels = target_labels.sort_values(by='resid')\n",
    "        \n",
    "        # Check if we have the expected number of residues\n",
    "        if len(target_labels) == len(sequence):\n",
    "            # Extract coordinates for each residue\n",
    "            coordinates = target_labels[['x_1', 'y_1', 'z_1']].values\n",
    "            \n",
    "            # Create a mask for NaN values (1 for valid, 0 for NaN)\n",
    "            valid_mask = ~np.isnan(coordinates).any(axis=1)\n",
    "            mask = torch.tensor(valid_mask, dtype=torch.float)\n",
    "            \n",
    "            # Replace NaN with zeros (we'll mask these during loss calculation)\n",
    "            coordinates = np.nan_to_num(coordinates, nan=0.0)\n",
    "            \n",
    "            y = torch.tensor(coordinates, dtype=torch.float)\n",
    "        else:\n",
    "            print(f\"Warning: Mismatch in sequence length and label count for {target_id}\")\n",
    "    \n",
    "    # Create the data object with properly typed target_id (as string)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y, mask=mask)\n",
    "    \n",
    "    # Store target_id as a string attribute\n",
    "    data.target_id = str(target_id)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97e40ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.781500Z",
     "iopub.status.busy": "2025-03-18T21:30:41.781128Z",
     "iopub.status.idle": "2025-03-18T21:30:41.788778Z",
     "shell.execute_reply": "2025-03-18T21:30:41.787692Z"
    },
    "papermill": {
     "duration": 0.018896,
     "end_time": "2025-03-18T21:30:41.790258",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.771362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(sequences_df, labels_df=None):\n",
    "    dataset = []\n",
    "    skipped_count = 0\n",
    "    nan_count = 0\n",
    "    \n",
    "    for idx, row in tqdm(sequences_df.iterrows(), total=len(sequences_df)):\n",
    "        target_id = row['target_id']\n",
    "        sequence = row['sequence']\n",
    "        \n",
    "        # Clean sequence - replace any non-standard nucleotides with 'N'\n",
    "        # and count how many non-standard nucleotides there are\n",
    "        cleaned_sequence = ''\n",
    "        non_standard_count = 0\n",
    "        \n",
    "        for nt in sequence:\n",
    "            if nt in nucleotide_mapping:\n",
    "                cleaned_sequence += nt\n",
    "            else:\n",
    "                cleaned_sequence += 'N'  # Placeholder for non-standard nucleotides\n",
    "                non_standard_count += 1\n",
    "        \n",
    "        # If too many non-standard nucleotides (>10%), skip this sequence\n",
    "        if non_standard_count / len(sequence) > 0.1:\n",
    "            print(f\"Skipping sequence {target_id} with {non_standard_count} non-standard nucleotides\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Create graph\n",
    "        graph = sequence_to_graph(cleaned_sequence, target_id, labels_df)\n",
    "        \n",
    "        # Check if we have labels with many NaN values\n",
    "        if labels_df is not None and hasattr(graph, 'mask') and graph.mask is not None:\n",
    "            nan_percentage = 1.0 - torch.mean(graph.mask).item()\n",
    "            if nan_percentage > 0.5:  # If more than 50% coordinates are NaN\n",
    "                print(f\"Warning: Sequence {target_id} has {nan_percentage:.1%} NaN coordinates\")\n",
    "                nan_count += 1\n",
    "        \n",
    "        # Add to dataset if no labels needed or valid labels exist\n",
    "        if labels_df is None or graph.y is not None:\n",
    "            dataset.append(graph)\n",
    "    \n",
    "    print(f\"Dataset creation: {skipped_count} sequences skipped due to non-standard nucleotides\")\n",
    "    print(f\"Dataset creation: {nan_count} sequences have >50% NaN coordinates\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "588d9533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.809096Z",
     "iopub.status.busy": "2025-03-18T21:30:41.808756Z",
     "iopub.status.idle": "2025-03-18T21:30:41.817359Z",
     "shell.execute_reply": "2025-03-18T21:30:41.816515Z"
    },
    "papermill": {
     "duration": 0.019814,
     "end_time": "2025-03-18T21:30:41.818916",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.799102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data={\n",
    "      \"sequence\":train_sequences['sequence'].to_list(),\n",
    "      \"temporal_cutoff\": train_sequences['temporal_cutoff'].to_list(),\n",
    "      \"description\": train_sequences['description'].to_list(),\n",
    "      \"all_sequences\": train_sequences['all_sequences'].to_list(),\n",
    "}\n",
    "config = {\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b23b6f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.837065Z",
     "iopub.status.busy": "2025-03-18T21:30:41.836766Z",
     "iopub.status.idle": "2025-03-18T21:30:41.844466Z",
     "shell.execute_reply": "2025-03-18T21:30:41.843674Z"
    },
    "papermill": {
     "duration": 0.018448,
     "end_time": "2025-03-18T21:30:41.845951",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.827503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "all_index = np.arange(len(data['sequence']))\n",
    "cutoff_date = pd.Timestamp(config['cutoff_date'])\n",
    "test_cutoff_date = pd.Timestamp(config['test_cutoff_date'])\n",
    "train_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) <= cutoff_date]\n",
    "test_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) > cutoff_date and pd.Timestamp(d) <= test_cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31712e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:30:41.863613Z",
     "iopub.status.busy": "2025-03-18T21:30:41.863298Z",
     "iopub.status.idle": "2025-03-18T21:31:13.484119Z",
     "shell.execute_reply": "2025-03-18T21:31:13.483018Z"
    },
    "papermill": {
     "duration": 31.631481,
     "end_time": "2025-03-18T21:31:13.485818",
     "exception": false,
     "start_time": "2025-03-18T21:30:41.854337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 113/844 [00:04<00:25, 29.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 1LS2_B has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 134/844 [00:04<00:24, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 1P6V_D has 64.7% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 140/844 [00:04<00:24, 28.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 1QZC_C has 100.0% NaN coordinates\n",
      "Warning: Sequence 1R2W_C has 100.0% NaN coordinates\n",
      "Warning: Sequence 1QZC_B has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 147/844 [00:05<00:23, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 1QZA_B has 100.0% NaN coordinates\n",
      "Warning: Sequence 1QZB_B has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 169/844 [00:05<00:23, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 1Y1Y_P has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 178/844 [00:06<00:22, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 1ZC8_Z has 100.0% NaN coordinates\n",
      "Warning: Sequence 1ZC8_G has 100.0% NaN coordinates\n",
      "Warning: Sequence 1ZC8_J has 100.0% NaN coordinates\n",
      "Warning: Sequence 1ZC8_F has 100.0% NaN coordinates\n",
      "Warning: Sequence 1ZC8_I has 100.0% NaN coordinates\n",
      "Warning: Sequence 1ZC8_H has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 184/844 [00:06<00:22, 28.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 1X18_D has 100.0% NaN coordinates\n",
      "Warning: Sequence 1X18_A has 100.0% NaN coordinates\n",
      "Warning: Sequence 1X18_B has 100.0% NaN coordinates\n",
      "Warning: Sequence 1ZN1_B has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 208/844 [00:07<00:22, 28.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 2BS0_S has 55.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 217/844 [00:07<00:27, 23.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 2AGN_C has 100.0% NaN coordinates\n",
      "Warning: Sequence 2AGN_A has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 235/844 [00:08<00:22, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 2IY3_B has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 244/844 [00:08<00:27, 21.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 2OB7_D has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 283/844 [00:10<00:19, 28.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 2R1G_C has 100.0% NaN coordinates\n",
      "Warning: Sequence 2R1G_A has 100.0% NaN coordinates\n",
      "Warning: Sequence 2R1G_X has 100.0% NaN coordinates\n",
      "Warning: Sequence 2R1G_F has 100.0% NaN coordinates\n",
      "Warning: Sequence 2R1G_B has 100.0% NaN coordinates\n",
      "Warning: Sequence 2R1G_E has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 304/844 [00:11<00:20, 26.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 3EQ3_E has 100.0% NaN coordinates\n",
      "Warning: Sequence 3EQ3_Y has 100.0% NaN coordinates\n",
      "Warning: Sequence 3EP2_B has 100.0% NaN coordinates\n",
      "Warning: Sequence 3EP2_D has 100.0% NaN coordinates\n",
      "Warning: Sequence 3EQ4_A has 100.0% NaN coordinates\n",
      "Warning: Sequence 3EP2_C has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 313/844 [00:11<00:20, 26.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 3CW1_v has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 346/844 [00:12<00:19, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 3PGW_N has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 427/844 [00:15<00:15, 27.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 4V5Z_BP has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 442/844 [00:16<00:15, 26.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 4V5Z_BA has 100.0% NaN coordinates\n",
      "Warning: Sequence 4V5Z_BH has 100.0% NaN coordinates\n",
      "Warning: Sequence 4V5Z_BL has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 451/844 [00:16<00:14, 26.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 4V5Z_BC has 100.0% NaN coordinates\n",
      "Warning: Sequence 4V5Z_BK has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 457/844 [00:16<00:14, 26.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 4V5Z_AH has 100.0% NaN coordinates\n",
      "Warning: Sequence 4V5Z_BU has 100.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 463/844 [00:16<00:14, 26.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 4V5Z_BQ has 100.0% NaN coordinates\n",
      "Warning: Sequence 4V5Z_AF has 100.0% NaN coordinates\n",
      "Warning: Sequence 4V5Z_BM has 100.0% NaN coordinates\n",
      "Warning: Sequence 4OQ9_3 has 90.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 508/844 [00:18<00:12, 27.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 5GAP_U has 90.7% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 580/844 [00:21<00:10, 26.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 6IV6_G has 55.9% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 595/844 [00:21<00:09, 26.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 6HYU_D has 66.7% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 616/844 [00:22<00:08, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 6WB1_C has 68.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 643/844 [00:23<00:07, 26.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 6Y0C_IN1 has 59.2% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 673/844 [00:24<00:06, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 6WW6_E has 68.5% NaN coordinates\n",
      "Warning: Sequence 6WW6_F has 68.5% NaN coordinates\n",
      "Warning: Sequence 6WW6_C has 66.7% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 679/844 [00:25<00:06, 26.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 7M57_ii has 63.0% NaN coordinates\n",
      "Warning: Sequence 7M2T_ss has 74.1% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 691/844 [00:25<00:05, 27.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 7SLP_R has 54.3% NaN coordinates\n",
      "Warning: Sequence 7S3H_R has 70.6% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 790/844 [00:29<00:02, 25.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 8P0B_V has 62.5% NaN coordinates\n",
      "Warning: Sequence 8P0G_V has 60.0% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 805/844 [00:30<00:01, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 8WT6_E has 67.2% NaN coordinates\n",
      "Warning: Sequence 8WT8_F has 62.2% NaN coordinates\n",
      "Warning: Sequence 8WT8_E has 67.2% NaN coordinates\n",
      "Warning: Sequence 8WT6_F has 62.2% NaN coordinates\n",
      "Warning: Sequence 8WT7_E has 67.2% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 811/844 [00:30<00:01, 25.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Sequence 8WT7_F has 62.2% NaN coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 844/844 [00:31<00:00, 26.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creation: 0 sequences skipped due to non-standard nucleotides\n",
      "Dataset creation: 69 sequences have >50% NaN coordinates\n",
      "Created 844 graph data objects for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset\n",
    "train_dataset = create_dataset(train_sequences, train_labels)\n",
    "print(f\"Created {len(train_dataset)} graph data objects for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc31f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:13.534501Z",
     "iopub.status.busy": "2025-03-18T21:31:13.534170Z",
     "iopub.status.idle": "2025-03-18T21:31:13.538210Z",
     "shell.execute_reply": "2025-03-18T21:31:13.537237Z"
    },
    "papermill": {
     "duration": 0.029743,
     "end_time": "2025-03-18T21:31:13.539686",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.509943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_graphs = train_dataset[:len(train_index)]\n",
    "val_graphs = train_dataset[:len(train_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec965e1f",
   "metadata": {
    "papermill": {
     "duration": 0.02554,
     "end_time": "2025-03-18T21:31:13.589779",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.564239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7acbc3",
   "metadata": {
    "papermill": {
     "duration": 0.02332,
     "end_time": "2025-03-18T21:31:13.636449",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.613129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab88dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:13.684188Z",
     "iopub.status.busy": "2025-03-18T21:31:13.683863Z",
     "iopub.status.idle": "2025-03-18T21:31:13.692191Z",
     "shell.execute_reply": "2025-03-18T21:31:13.691425Z"
    },
    "papermill": {
     "duration": 0.033484,
     "end_time": "2025-03-18T21:31:13.693362",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.659878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the GNN model\n",
    "class RNAStructurePredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, output_dim=3, num_layers=10, max_seq_len=MAX_SEQ_LEN):\n",
    "        super(RNAStructurePredictor, self).__init__()\n",
    "        \n",
    "        # Initial embedding layer\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # SAGEConv layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.conv_layers.append(SAGEConv(hidden_dim, hidden_dim))\n",
    "        \n",
    "        # Output layer for 3D coordinates prediction (x, y, z)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Add attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Position encoding - increase max sequence length\n",
    "        self.position_encoder = nn.Embedding(max_seq_len, hidden_dim)\n",
    "        \n",
    "        # Initialize parameters with Xavier/Glorot\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # Initial embedding\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Add positional information with bounds checking\n",
    "        max_pos = self.position_encoder.weight.size(0) - 1  # Maximum allowed index\n",
    "        pos = torch.arange(x.size(0), device=x.device)\n",
    "        # Clamp position indices to avoid out-of-bounds errors\n",
    "        pos = torch.clamp(pos, max=max_pos)\n",
    "        x = x + self.position_encoder(pos)\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        for conv in self.conv_layers:\n",
    "            x_residual = x\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = x + x_residual  # Skip connection\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        # Apply attention\n",
    "        attention_weights = self.attention(x)\n",
    "        x = x * attention_weights\n",
    "        \n",
    "        # Predict 3D coordinates\n",
    "        coordinates = self.output(x)\n",
    "        \n",
    "        return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f843a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:13.740788Z",
     "iopub.status.busy": "2025-03-18T21:31:13.740396Z",
     "iopub.status.idle": "2025-03-18T21:31:13.745540Z",
     "shell.execute_reply": "2025-03-18T21:31:13.744610Z"
    },
    "papermill": {
     "duration": 0.030514,
     "end_time": "2025-03-18T21:31:13.747121",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.716607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function for 3D coordinate prediction\n",
    "def rmsd_loss(pred, target, mask=None):\n",
    "    \"\"\"\n",
    "    Root Mean Square Deviation (RMSD) loss function with optional masking for NaN values.\n",
    "    Lower RMSD indicates better structural similarity.\n",
    "    \n",
    "    Args:\n",
    "        pred: Predicted coordinates, shape (n_nucleotides, 3)\n",
    "        target: Target coordinates, shape (n_nucleotides, 3)\n",
    "        mask: Optional mask for valid values, shape (n_nucleotides,)\n",
    "    \"\"\"\n",
    "    squared_diff = torch.sum((pred - target) ** 2, dim=1)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # Apply mask to consider only valid coordinates\n",
    "        # Ensure we don't divide by zero by adding a small epsilon to the sum\n",
    "        masked_squared_diff = squared_diff * mask\n",
    "        mean_squared_diff = torch.sum(masked_squared_diff) / (torch.sum(mask) + 1e-10)\n",
    "    else:\n",
    "        mean_squared_diff = torch.mean(squared_diff)\n",
    "    \n",
    "    rmsd = torch.sqrt(mean_squared_diff)\n",
    "    return rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a2e3933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:13.795960Z",
     "iopub.status.busy": "2025-03-18T21:31:13.795613Z",
     "iopub.status.idle": "2025-03-18T21:31:13.807535Z",
     "shell.execute_reply": "2025-03-18T21:31:13.806717Z"
    },
    "papermill": {
     "duration": 0.038356,
     "end_time": "2025-03-18T21:31:13.809058",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.770702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X,Y,epsilon=1e-4):\n",
    "    return (torch.square(X[:,None]-Y[None,:])+epsilon).sum(-1).sqrt()\n",
    "\n",
    "\n",
    "def dRMSD(pred_x,\n",
    "          pred_y,\n",
    "          gt_x,\n",
    "          gt_y,\n",
    "          epsilon=1e-4,Z=10,d_clamp=None):\n",
    "    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n",
    "    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n",
    "\n",
    "\n",
    "\n",
    "    mask=~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0]).bool()]=False\n",
    "\n",
    "    if d_clamp is not None:\n",
    "        rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).clip(0,d_clamp**2)\n",
    "    else:\n",
    "        rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n",
    "\n",
    "    return rmsd.sqrt().mean()/Z\n",
    "\n",
    "def local_dRMSD(pred_x,\n",
    "          pred_y,\n",
    "          gt_x,\n",
    "          gt_y,\n",
    "          epsilon=1e-4,Z=10,d_clamp=30):\n",
    "    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n",
    "    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n",
    "\n",
    "\n",
    "\n",
    "    mask=(~torch.isnan(gt_dm))*(gt_dm<d_clamp)\n",
    "    mask[torch.eye(mask.shape[0]).bool()]=False\n",
    "\n",
    "\n",
    "\n",
    "    rmsd=torch.square(pred_dm[mask]-gt_dm[mask])+epsilon\n",
    "    # rmsd=(torch.square(pred_dm[mask]-gt_dm[mask])+epsilon).sqrt()/Z\n",
    "    #rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])/Z\n",
    "    return rmsd.sqrt().mean()/Z\n",
    "\n",
    "def dRMAE(pred_x,\n",
    "          pred_y,\n",
    "          gt_x,\n",
    "          gt_y,\n",
    "          epsilon=1e-4,Z=10,d_clamp=None):\n",
    "    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n",
    "    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n",
    "\n",
    "\n",
    "\n",
    "    mask=~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0]).bool()]=False\n",
    "\n",
    "    rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])\n",
    "\n",
    "    return rmsd.mean()/Z\n",
    "\n",
    "import torch\n",
    "\n",
    "def align_svd_mae(input, target, Z=10):\n",
    "    \"\"\"\n",
    "    Aligns the input (Nx3) to target (Nx3) using SVD-based Procrustes alignment\n",
    "    and computes RMSD loss.\n",
    "    \n",
    "    Args:\n",
    "        input (torch.Tensor): Nx3 tensor representing the input points.\n",
    "        target (torch.Tensor): Nx3 tensor representing the target points.\n",
    "    \n",
    "    Returns:\n",
    "        aligned_input (torch.Tensor): Nx3 aligned input.\n",
    "        rmsd_loss (torch.Tensor): RMSD loss.\n",
    "    \"\"\"\n",
    "    assert input.shape == target.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    #mask \n",
    "    mask=~torch.isnan(target.sum(-1))\n",
    "\n",
    "    input=input[mask]\n",
    "    target=target[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input - centroid_input.detach()\n",
    "    target_centered = target - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "\n",
    "    # Compute rotation matrix\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (det(R) = 1, no reflection)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt @ U.T\n",
    "\n",
    "    # Rotate input\n",
    "    aligned_input = (input_centered @ R.T.detach()) + centroid_target.detach()\n",
    "\n",
    "    # # Compute RMSD loss\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "    \n",
    "    # return aligned_input, rmsd_loss\n",
    "    return torch.abs(aligned_input-target).mean()/Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb9da52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:13.857560Z",
     "iopub.status.busy": "2025-03-18T21:31:13.857208Z",
     "iopub.status.idle": "2025-03-18T21:31:13.865956Z",
     "shell.execute_reply": "2025-03-18T21:31:13.865119Z"
    },
    "papermill": {
     "duration": 0.034959,
     "end_time": "2025-03-18T21:31:13.867481",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.832522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loss_values = []\n",
    "    # Create tqdm progress bar with loss display\n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for data in pbar:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(data)\n",
    "        \n",
    "        # Calculate loss if labels exist\n",
    "        if data.y is not None:\n",
    "            # Use mask if available\n",
    "            if hasattr(data, 'mask') and data.mask is not None:\n",
    "                loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n",
    "                # loss = rmsd_loss(pred, data.y, data.mask)\n",
    "            else:\n",
    "                loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n",
    "                # loss = rmsd_loss(pred, data.y)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            loss_values.append(loss.item())\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'smooth loss': np.mean(loss_values[-100:])})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Create tqdm progress bar with loss display\n",
    "    pbar = tqdm(val_loader, desc='Validation')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in pbar:\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            \n",
    "            if data.y is not None:\n",
    "                # Use mask if available\n",
    "                if hasattr(data, 'mask') and data.mask is not None:\n",
    "                    loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n",
    "                    # loss = rmsd_loss(pred, data.y, data.mask)\n",
    "                else:\n",
    "                    loss = dRMAE(pred,pred,data.y,data.y) + align_svd_mae(pred, data.y)\n",
    "                    # loss = rmsd_loss(pred, data.y)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Update progress bar with current loss\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d298df36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:13.917026Z",
     "iopub.status.busy": "2025-03-18T21:31:13.916630Z",
     "iopub.status.idle": "2025-03-18T21:31:13.922375Z",
     "shell.execute_reply": "2025-03-18T21:31:13.921617Z"
    },
    "papermill": {
     "duration": 0.032272,
     "end_time": "2025-03-18T21:31:13.923883",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.891611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to make predictions on test data\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            \n",
    "            # Store predictions\n",
    "            target_id = data.target_id\n",
    "            \n",
    "            # If we have ground truth and mask, report metrics\n",
    "            if hasattr(data, 'y') and data.y is not None:\n",
    "                if hasattr(data, 'mask') and data.mask is not None:\n",
    "                    loss = rmsd_loss(pred, data.y, data.mask).item()\n",
    "                else:\n",
    "                    loss = rmsd_loss(pred, data.y).item()\n",
    "                print(f\"Prediction for {target_id}, RMSD: {loss:.4f}\")\n",
    "            \n",
    "            predictions[target_id] = pred.cpu().numpy()\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661f46a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:13.973422Z",
     "iopub.status.busy": "2025-03-18T21:31:13.973115Z",
     "iopub.status.idle": "2025-03-18T21:31:13.978547Z",
     "shell.execute_reply": "2025-03-18T21:31:13.977504Z"
    },
    "papermill": {
     "duration": 0.032031,
     "end_time": "2025-03-18T21:31:13.980191",
     "exception": false,
     "start_time": "2025-03-18T21:31:13.948160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup for training\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "device = torch.device(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72a96a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:14.026351Z",
     "iopub.status.busy": "2025-03-18T21:31:14.026040Z",
     "iopub.status.idle": "2025-03-18T21:31:14.031771Z",
     "shell.execute_reply": "2025-03-18T21:31:14.030718Z"
    },
    "papermill": {
     "duration": 0.029999,
     "end_time": "2025-03-18T21:31:14.033244",
     "exception": false,
     "start_time": "2025-03-18T21:31:14.003245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_graphs, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_graphs, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfbda659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:14.080075Z",
     "iopub.status.busy": "2025-03-18T21:31:14.079764Z",
     "iopub.status.idle": "2025-03-18T21:31:14.993870Z",
     "shell.execute_reply": "2025-03-18T21:31:14.992485Z"
    },
    "papermill": {
     "duration": 0.939162,
     "end_time": "2025-03-18T21:31:14.995512",
     "exception": false,
     "start_time": "2025-03-18T21:31:14.056350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with max sequence length of 10000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_dim = 4  # One-hot encoding dimension for nucleotides\n",
    "model = RNAStructurePredictor(input_dim, hidden_dim=1024, output_dim=3, num_layers=15, max_seq_len=10000).to(device)\n",
    "print(f\"Model initialized with max sequence length of 10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b167ccbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:15.043866Z",
     "iopub.status.busy": "2025-03-18T21:31:15.043366Z",
     "iopub.status.idle": "2025-03-18T21:31:15.048462Z",
     "shell.execute_reply": "2025-03-18T21:31:15.047706Z"
    },
    "papermill": {
     "duration": 0.029976,
     "end_time": "2025-03-18T21:31:15.049722",
     "exception": false,
     "start_time": "2025-03-18T21:31:15.019746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00003)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a939e1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:31:15.148936Z",
     "iopub.status.busy": "2025-03-18T21:31:15.148529Z",
     "iopub.status.idle": "2025-03-18T21:58:40.268252Z",
     "shell.execute_reply": "2025-03-18T21:58:40.266771Z"
    },
    "papermill": {
     "duration": 1645.196381,
     "end_time": "2025-03-18T21:58:40.269986",
     "exception": false,
     "start_time": "2025-03-18T21:31:15.073605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:09<00:00,  8.36it/s, loss=7.1510, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.73it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 18.5489, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.10it/s, loss=2.9815, smooth loss=17.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.85it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2000, Train Loss: 17.6925, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:07<00:00, 10.49it/s, loss=5.1950, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.68it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/2000, Train Loss: 17.8774, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.30it/s, loss=3.8799, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.43it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/2000, Train Loss: 18.1151, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.43it/s, loss=2.8164, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.37it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/2000, Train Loss: 18.5997, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.42it/s, loss=9.4302, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.17it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/2000, Train Loss: 17.9282, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.76it/s, loss=11.2863, smooth loss=17.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.87it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/2000, Train Loss: 17.8089, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.58it/s, loss=2.7140, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.72it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/2000, Train Loss: 18.1212, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.65it/s, loss=3.2506, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.78it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/2000, Train Loss: 18.1055, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.18it/s, loss=3.2058, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.78it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000, Train Loss: 17.9360, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.36it/s, loss=8.1641, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.88it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/2000, Train Loss: 18.2748, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.46it/s, loss=5.6264, smooth loss=19.5]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.10it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/2000, Train Loss: 19.5480, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.39it/s, loss=6.4467, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.81it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/2000, Train Loss: 17.9748, Val Loss: 13.3715, LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.70it/s, loss=25.5335, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.38it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/2000, Train Loss: 18.4801, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.51it/s, loss=21.0850, smooth loss=19]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.54it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/2000, Train Loss: 18.9708, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.02it/s, loss=2.0128, smooth loss=17.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.22it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/2000, Train Loss: 17.7144, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.46it/s, loss=18.0775, smooth loss=19]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.29it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/2000, Train Loss: 18.9832, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.27it/s, loss=0.8955, smooth loss=19.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.24it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/2000, Train Loss: 19.1089, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.33it/s, loss=7.6478, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.57it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/2000, Train Loss: 18.2845, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.32it/s, loss=2.9936, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.44it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/2000, Train Loss: 17.9747, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.51it/s, loss=16.1580, smooth loss=19.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.77it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/2000, Train Loss: 19.2503, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.55it/s, loss=12.1986, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.82it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/2000, Train Loss: 18.5548, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.64it/s, loss=8.8808, smooth loss=17]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.58it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/2000, Train Loss: 17.0259, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.22it/s, loss=7.8038, smooth loss=19.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.56it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/2000, Train Loss: 19.3053, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.41it/s, loss=3.7466, smooth loss=19.2]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.54it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/2000, Train Loss: 19.1864, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.53it/s, loss=16.3719, smooth loss=18.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.67it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/2000, Train Loss: 18.6942, Val Loss: 13.3715, LR: 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.20it/s, loss=3.1368, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.62it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/2000, Train Loss: 18.5485, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.44it/s, loss=1.3284, smooth loss=17.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.36it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/2000, Train Loss: 17.5395, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.38it/s, loss=1.1960, smooth loss=19.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.75it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/2000, Train Loss: 19.8831, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.54it/s, loss=19.2521, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.46it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/2000, Train Loss: 18.4676, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.95it/s, loss=6.6708, smooth loss=18.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.92it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/2000, Train Loss: 18.7743, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.54it/s, loss=34.9586, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.65it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/2000, Train Loss: 17.8974, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.52it/s, loss=7.7592, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.15it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/2000, Train Loss: 18.3678, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.11it/s, loss=6.6550, smooth loss=19.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.28it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/2000, Train Loss: 19.3318, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.68it/s, loss=21.9965, smooth loss=17.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.68it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/2000, Train Loss: 17.3515, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.74it/s, loss=1.7498, smooth loss=17.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.88it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/2000, Train Loss: 17.5885, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.25it/s, loss=26.4492, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.30it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/2000, Train Loss: 18.3094, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.69it/s, loss=17.6762, smooth loss=17.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.75it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/2000, Train Loss: 17.6109, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.46it/s, loss=5.7311, smooth loss=19.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.76it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/2000, Train Loss: 19.7419, Val Loss: 13.3715, LR: 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.35it/s, loss=5.3899, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.50it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/2000, Train Loss: 18.0563, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.71it/s, loss=12.8253, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 19.00it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/2000, Train Loss: 18.6213, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.38it/s, loss=13.2026, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.37it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/2000, Train Loss: 18.0490, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.68it/s, loss=11.6778, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.71it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/2000, Train Loss: 18.3275, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.56it/s, loss=3.2803, smooth loss=17.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.37it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/2000, Train Loss: 17.5942, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=4.3228, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.75it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/2000, Train Loss: 18.2693, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.43it/s, loss=3.7723, smooth loss=18.8]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.01it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/2000, Train Loss: 18.7982, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.69it/s, loss=7.8030, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.04it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/2000, Train Loss: 18.5994, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.54it/s, loss=6.9685, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 15.97it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/2000, Train Loss: 17.8760, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.11it/s, loss=25.6010, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.73it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/2000, Train Loss: 18.4381, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.41it/s, loss=12.6014, smooth loss=17.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.17it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/2000, Train Loss: 17.6116, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.24it/s, loss=18.6284, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.46it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/2000, Train Loss: 18.5067, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=5.9350, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.24it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/2000, Train Loss: 18.1100, Val Loss: 13.3715, LR: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.93it/s, loss=10.6145, smooth loss=19.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.39it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/2000, Train Loss: 19.6334, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.44it/s, loss=5.9034, smooth loss=19.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.68it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/2000, Train Loss: 19.1438, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.53it/s, loss=2.3544, smooth loss=18.2]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.03it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/2000, Train Loss: 18.1842, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.56it/s, loss=7.2104, smooth loss=18.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.82it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000, Train Loss: 18.9043, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.22it/s, loss=1.6479, smooth loss=18.7]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.03it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/2000, Train Loss: 18.6856, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.55it/s, loss=14.3530, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.10it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/2000, Train Loss: 18.1449, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.67it/s, loss=4.3608, smooth loss=18.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.82it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000, Train Loss: 18.8439, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.61it/s, loss=2.3710, smooth loss=17.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.59it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/2000, Train Loss: 17.7807, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.34it/s, loss=9.5153, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.78it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/2000, Train Loss: 18.3616, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.43it/s, loss=3.0160, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.84it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/2000, Train Loss: 17.8689, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.99it/s, loss=3.0122, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.28it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/2000, Train Loss: 18.2574, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.51it/s, loss=9.2709, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:03<00:00, 19.00it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/2000, Train Loss: 17.8544, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.30it/s, loss=11.8520, smooth loss=19.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.63it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/2000, Train Loss: 19.4808, Val Loss: 13.3715, LR: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.02it/s, loss=13.7626, smooth loss=19]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.16it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/2000, Train Loss: 19.0321, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.36it/s, loss=5.7589, smooth loss=17.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.27it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/2000, Train Loss: 17.6441, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.98it/s, loss=12.3444, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.96it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/2000, Train Loss: 17.9347, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.98it/s, loss=14.6388, smooth loss=17.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.67it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/2000, Train Loss: 17.3392, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.44it/s, loss=4.6071, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.38it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/2000, Train Loss: 18.2789, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=2.6625, smooth loss=18.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.11it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/2000, Train Loss: 18.7524, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.38it/s, loss=8.6630, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.41it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/2000, Train Loss: 18.4749, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.40it/s, loss=10.3777, smooth loss=18.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.05it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/2000, Train Loss: 18.6620, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:07<00:00, 10.74it/s, loss=4.8827, smooth loss=18.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.50it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/2000, Train Loss: 18.8183, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.32it/s, loss=12.0415, smooth loss=17.2]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.75it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/2000, Train Loss: 17.1713, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.21it/s, loss=18.7303, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.40it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/2000, Train Loss: 18.0547, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.62it/s, loss=4.6456, smooth loss=17.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.97it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/2000, Train Loss: 17.6667, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.27it/s, loss=28.9344, smooth loss=17.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.21it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/2000, Train Loss: 17.6506, Val Loss: 13.3715, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.99it/s, loss=5.3188, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.49it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/2000, Train Loss: 18.5559, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.08it/s, loss=15.7492, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.11it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/2000, Train Loss: 18.6120, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.54it/s, loss=7.4579, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.91it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/2000, Train Loss: 18.1390, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.75it/s, loss=6.0599, smooth loss=18.2]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.80it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/2000, Train Loss: 18.1655, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.32it/s, loss=7.7461, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.86it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/2000, Train Loss: 18.1456, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.51it/s, loss=11.5000, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.45it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/2000, Train Loss: 18.4396, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.54it/s, loss=5.2379, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.59it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/2000, Train Loss: 18.3955, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:07<00:00, 10.65it/s, loss=2.2321, smooth loss=17.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.46it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/2000, Train Loss: 17.8016, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.29it/s, loss=5.8281, smooth loss=19]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.08it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/2000, Train Loss: 18.9588, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.27it/s, loss=6.3182, smooth loss=19.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.29it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/2000, Train Loss: 19.2568, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.21it/s, loss=12.2130, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.90it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/2000, Train Loss: 18.2652, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.53it/s, loss=4.6643, smooth loss=17.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.23it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/2000, Train Loss: 17.7605, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.62it/s, loss=3.3974, smooth loss=17.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.40it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/2000, Train Loss: 17.1175, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.26it/s, loss=2.9300, smooth loss=18.2]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.59it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/2000, Train Loss: 18.2278, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.46it/s, loss=2.4008, smooth loss=19.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.60it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/2000, Train Loss: 19.1387, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.54it/s, loss=10.5175, smooth loss=17.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.04it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/2000, Train Loss: 17.3012, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.25it/s, loss=25.2874, smooth loss=19.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.86it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/2000, Train Loss: 19.4691, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.65it/s, loss=3.2803, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.88it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/2000, Train Loss: 18.0736, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.33it/s, loss=5.8048, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.57it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/2000, Train Loss: 18.4502, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.65it/s, loss=6.1741, smooth loss=18.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.81it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/2000, Train Loss: 18.7708, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.76it/s, loss=5.8608, smooth loss=18.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.57it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/2000, Train Loss: 18.7003, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.25it/s, loss=4.1958, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.62it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Train Loss: 18.5216, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.91it/s, loss=8.9523, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.70it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/2000, Train Loss: 17.9720, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.66it/s, loss=12.1356, smooth loss=19]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.51it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/2000, Train Loss: 19.0181, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.46it/s, loss=1.1288, smooth loss=17.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.43it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/2000, Train Loss: 17.3676, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.01it/s, loss=9.0872, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.23it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/2000, Train Loss: 18.0054, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.62it/s, loss=3.9245, smooth loss=19.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.47it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/2000, Train Loss: 19.0591, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=10.0387, smooth loss=18.2]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.59it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/2000, Train Loss: 18.1611, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:07<00:00, 10.67it/s, loss=12.5621, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.38it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/2000, Train Loss: 18.2947, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.17it/s, loss=10.8958, smooth loss=19]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.48it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/2000, Train Loss: 19.0410, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:07<00:00, 10.79it/s, loss=2.9379, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.37it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/2000, Train Loss: 18.0257, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:07<00:00, 10.79it/s, loss=11.8962, smooth loss=18.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.33it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/2000, Train Loss: 18.8805, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.22it/s, loss=2.8528, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.43it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/2000, Train Loss: 18.6408, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.18it/s, loss=1.1098, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.94it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/2000, Train Loss: 17.9887, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.54it/s, loss=14.6319, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.72it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/2000, Train Loss: 18.6362, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.29it/s, loss=12.4097, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.54it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/2000, Train Loss: 18.5734, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.52it/s, loss=3.7081, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.05it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/2000, Train Loss: 18.1248, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=8.1935, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.72it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/2000, Train Loss: 18.6273, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.22it/s, loss=3.2407, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.58it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000, Train Loss: 18.3515, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.30it/s, loss=2.0948, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.18it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/2000, Train Loss: 17.9250, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.90it/s, loss=6.5663, smooth loss=17.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.96it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/2000, Train Loss: 17.5328, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.42it/s, loss=34.0577, smooth loss=17.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.64it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/2000, Train Loss: 17.4985, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.32it/s, loss=11.2770, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.00it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/2000, Train Loss: 18.5270, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.67it/s, loss=10.5080, smooth loss=19.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.63it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/2000, Train Loss: 19.4897, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.29it/s, loss=1.2976, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.62it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/2000, Train Loss: 18.5728, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.43it/s, loss=2.4253, smooth loss=19.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.35it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/2000, Train Loss: 19.3417, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.47it/s, loss=11.7596, smooth loss=17.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.91it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/2000, Train Loss: 17.1438, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.68it/s, loss=6.2929, smooth loss=17.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.29it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/2000, Train Loss: 17.5810, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.53it/s, loss=8.5302, smooth loss=18.5]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.03it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/2000, Train Loss: 18.4776, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.68it/s, loss=11.3402, smooth loss=18.8]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.34it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/2000, Train Loss: 18.7688, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.41it/s, loss=49.9336, smooth loss=19.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.65it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/2000, Train Loss: 19.3100, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.92it/s, loss=2.5661, smooth loss=17.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.66it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/2000, Train Loss: 17.6528, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.02it/s, loss=8.7111, smooth loss=19.2]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 17.81it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/2000, Train Loss: 19.2072, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=9.5819, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.76it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/2000, Train Loss: 18.4171, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.28it/s, loss=33.8673, smooth loss=18.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.04it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/2000, Train Loss: 18.9068, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.59it/s, loss=2.5367, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.41it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/2000, Train Loss: 18.1350, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.18it/s, loss=4.6239, smooth loss=18.1]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.27it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/2000, Train Loss: 18.1069, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.00it/s, loss=9.6144, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.54it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/2000, Train Loss: 18.4094, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.65it/s, loss=7.2970, smooth loss=18.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.32it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/2000, Train Loss: 18.7280, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.53it/s, loss=9.0461, smooth loss=18]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.91it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/2000, Train Loss: 18.0189, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.02it/s, loss=16.7542, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.45it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/2000, Train Loss: 18.2535, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.03it/s, loss=11.9609, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.54it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/2000, Train Loss: 18.5634, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.55it/s, loss=0.4239, smooth loss=17.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.92it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/2000, Train Loss: 17.6531, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.20it/s, loss=4.7721, smooth loss=18.4]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.41it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/2000, Train Loss: 18.3844, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.95it/s, loss=12.7290, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.63it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/2000, Train Loss: 18.2901, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.42it/s, loss=11.4677, smooth loss=18.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 15.57it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/2000, Train Loss: 18.8604, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.88it/s, loss=2.0507, smooth loss=18.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.08it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/2000, Train Loss: 18.6573, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.57it/s, loss=3.7702, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.33it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/2000, Train Loss: 18.3458, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.28it/s, loss=1.0848, smooth loss=18.7]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.21it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/2000, Train Loss: 18.6739, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.46it/s, loss=9.3160, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.36it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/2000, Train Loss: 18.3014, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 10.92it/s, loss=13.6567, smooth loss=18.3]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.71it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/2000, Train Loss: 18.3431, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.42it/s, loss=6.9316, smooth loss=18.6]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 16.99it/s, loss=21.8392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/2000, Train Loss: 18.6160, Val Loss: 13.3715, LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:06<00:00, 11.35it/s, loss=1.6645, smooth loss=17.9]\n",
      "Validation: 100%|██████████| 76/76 [00:04<00:00, 18.11it/s, loss=21.8392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/2000, Train Loss: 17.9398, Val Loss: 13.3715, LR: 0.000000\n",
      "Early stopping triggered after 151 epochs\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 2000\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_patience = 150\n",
    "early_stopping_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), \"best_rna_structure_model.pt\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, \"\n",
    "          f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d1947fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:58:43.773989Z",
     "iopub.status.busy": "2025-03-18T21:58:43.773540Z",
     "iopub.status.idle": "2025-03-18T21:58:44.071122Z",
     "shell.execute_reply": "2025-03-18T21:58:44.070155Z"
    },
    "papermill": {
     "duration": 2.05675,
     "end_time": "2025-03-18T21:58:44.073095",
     "exception": false,
     "start_time": "2025-03-18T21:58:42.016345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training and validation losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSD Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('training_loss.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7acecbda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:58:47.474679Z",
     "iopub.status.busy": "2025-03-18T21:58:47.474310Z",
     "iopub.status.idle": "2025-03-18T21:58:47.489059Z",
     "shell.execute_reply": "2025-03-18T21:58:47.488242Z"
    },
    "papermill": {
     "duration": 1.728068,
     "end_time": "2025-03-18T21:58:47.490327",
     "exception": false,
     "start_time": "2025-03-18T21:58:45.762259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate multiple conformations for each RNA sequence\n",
    "def generate_multiple_conformations(model, data, num_conformations=5):\n",
    "    \"\"\"\n",
    "    Generate multiple structural conformations for an RNA sequence.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained GNN model\n",
    "        data: Graph data object containing the RNA sequence\n",
    "        num_conformations: Number of conformations to generate (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of numpy arrays, each array has shape (n_nucleotides, 3) for x,y,z coordinates\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    conformations = []\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate first conformation (deterministic)\n",
    "        base_pred = model(data)\n",
    "        base_np = base_pred.cpu().numpy()\n",
    "        \n",
    "        # Check if base prediction contains NaN values\n",
    "        if np.isnan(base_np).any():\n",
    "            print(\"Warning: Base prediction contains NaN values. Replacing with zeros.\")\n",
    "            base_np = np.nan_to_num(base_np, nan=0.0)\n",
    "        \n",
    "        # Save the base prediction\n",
    "        conformations.append(base_np)\n",
    "        \n",
    "        # Generate additional conformations with controlled variations\n",
    "        for i in range(1, num_conformations):\n",
    "            # Use different seeds for different conformations\n",
    "            torch.manual_seed(42 + i * 100)  # Larger seed increment for more diversity\n",
    "            \n",
    "            # Create a copy of the base prediction with a small, controlled variation\n",
    "            variation = base_np.copy()\n",
    "            \n",
    "            # Add random noise with small magnitude (1-5% of the coordinate values)\n",
    "            # Calculate standard deviation of base coordinates to scale noise appropriately\n",
    "            if not np.all(base_np == 0):  # Check if base_np is not all zeros\n",
    "                coord_std = max(np.std(base_np), 0.5)  # Use at least 0.5 to avoid too small noise\n",
    "                noise_scale = coord_std * 0.05 * (i + 1)  # Increasing noise for each conformation\n",
    "            else:\n",
    "                # If base prediction is all zeros (which shouldn't happen normally)\n",
    "                noise_scale = 0.5 * (i + 1)\n",
    "            \n",
    "            # Generate noise and ensure it's not NaN\n",
    "            noise = np.random.normal(0, noise_scale, size=variation.shape)\n",
    "            \n",
    "            # Apply noise to create a new conformation\n",
    "            variation += noise\n",
    "            \n",
    "            # Ensure no NaN values\n",
    "            variation = np.nan_to_num(variation, nan=0.0)\n",
    "            \n",
    "            conformations.append(variation)\n",
    "    \n",
    "    # Double-check that all conformations are valid and contain no NaNs\n",
    "    for i, conf in enumerate(conformations):\n",
    "        if np.isnan(conf).any():\n",
    "            print(f\"Warning: Conformation {i+1} contains NaN values after processing. Replacing with zeros.\")\n",
    "            conformations[i] = np.nan_to_num(conf, nan=0.0)\n",
    "    \n",
    "    return conformations\n",
    "\n",
    "# Function to make multiple predictions for test data\n",
    "def predict_multiple_conformations(model, test_loader, device, num_conformations=5):\n",
    "    predictions = {}\n",
    "    \n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        conformations = generate_multiple_conformations(model, data, num_conformations)\n",
    "        \n",
    "        # Store predictions - ensure target_id is a hashable type (string)\n",
    "        # The target_id could be stored as a list or other non-hashable type\n",
    "        if hasattr(data, 'target_id'):\n",
    "            # Convert to string if it's not already\n",
    "            if isinstance(data.target_id, list) and len(data.target_id) > 0:\n",
    "                target_id = str(data.target_id[0])  # Take the first element if it's a list\n",
    "            else:\n",
    "                target_id = str(data.target_id)  # Convert to string to ensure hashability\n",
    "        else:\n",
    "            # Generate a unique ID if none exists\n",
    "            target_id = f\"unknown_target_{len(predictions)}\"\n",
    "            \n",
    "        print(f\"Processing target: {target_id}\")\n",
    "        predictions[target_id] = conformations\n",
    "        \n",
    "        # If we have ground truth, report metrics for the first conformation\n",
    "        if hasattr(data, 'y') and data.y is not None and len(conformations) > 0:\n",
    "            first_conf = torch.tensor(conformations[0], device=device)\n",
    "            \n",
    "            if hasattr(data, 'mask') and data.mask is not None:\n",
    "                loss = rmsd_loss(first_conf, data.y, data.mask).item()\n",
    "            else:\n",
    "                loss = rmsd_loss(first_conf, data.y).item()\n",
    "                \n",
    "            print(f\"Prediction for {target_id}, RMSD of first conformation: {loss:.4f}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example of how to use the prediction function on test data\n",
    "def process_test_data(test_sequences_path):\n",
    "    # Load test sequences\n",
    "    test_sequences = pd.read_csv(test_sequences_path)\n",
    "    \n",
    "    # Create test dataset (without labels)\n",
    "    test_dataset = create_dataset(test_sequences)\n",
    "    \n",
    "    # Create test loader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = predict_multiple_conformations(model, test_loader, device)\n",
    "    \n",
    "    # Format predictions for submission\n",
    "    formatted_predictions = []\n",
    "    \n",
    "    for target_id, conformations in predictions.items():\n",
    "        for i, conformation in enumerate(conformations):\n",
    "            for j, coords in enumerate(conformation):\n",
    "                resid = j + 1  # 1-based indexing\n",
    "                row = {\n",
    "                    'ID': f\"{target_id}_{resid}\",\n",
    "                    f'x_{i+1}': coords[0],\n",
    "                    f'y_{i+1}': coords[1],\n",
    "                    f'z_{i+1}': coords[2]\n",
    "                }\n",
    "                formatted_predictions.append(row)\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission_df = pd.DataFrame(formatted_predictions)\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45124c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T21:58:51.049902Z",
     "iopub.status.busy": "2025-03-18T21:58:51.049507Z",
     "iopub.status.idle": "2025-03-18T21:58:56.428304Z",
     "shell.execute_reply": "2025-03-18T21:58:56.427452Z"
    },
    "papermill": {
     "duration": 7.152758,
     "end_time": "2025-03-18T21:58:56.430101",
     "exception": false,
     "start_time": "2025-03-18T21:58:49.277343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 126.35it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creation: 0 sequences skipped due to non-standard nucleotides\n",
      "Dataset creation: 0 sequences have >50% NaN coordinates\n",
      "Processing target: R1107\n",
      "Processing target: R1108\n",
      "Processing target: R1116\n",
      "Processing target: R1117v2\n",
      "Processing target: R1126\n",
      "Processing target: R1128\n",
      "Processing target: R1136\n",
      "Processing target: R1138\n",
      "Processing target: R1149\n",
      "Processing target: R1156\n",
      "Processing target: R1189\n",
      "Processing target: R1190\n"
     ]
    }
   ],
   "source": [
    "test_predictions = process_test_data(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")\n",
    "sub = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/sample_submission.csv\")\n",
    "DF_ROWS = []\n",
    "\n",
    "for i, row in sub.iterrows():\n",
    "    snap = test_predictions[test_predictions['ID'] == row['ID']]\n",
    "    x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5 = snap['x_1'], snap['y_1'], snap['z_1'], snap['x_2'], snap['y_2'], snap['z_2'], snap['x_3'], snap['y_3'], snap['z_3'], snap['x_4'], snap['y_4'], snap['z_4'], snap['x_5'], snap['y_5'], snap['z_5']\n",
    "    x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5 = x1.values[0], y1.values[0], z1.values[0], x2.values[1], y2.values[1], z2.values[1], x3.values[2], y3.values[2], z3.values[2], x4.values[3], y4.values[3], z4.values[3], x5.values[4], y5.values[4], z5.values[4]\n",
    "    _row = [x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5]\n",
    "    DF_ROWS.append(_row)\n",
    "sub[['x_1', 'y_1', 'z_1', 'x_2', 'y_2', 'z_2', 'x_3', 'y_3', 'z_3', 'x_4', 'y_4', 'z_4', 'x_5', 'y_5', 'z_5']] = DF_ROWS\n",
    "sub.head()\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740beebb",
   "metadata": {
    "papermill": {
     "duration": 1.770121,
     "end_time": "2025-03-18T21:59:00.008221",
     "exception": false,
     "start_time": "2025-03-18T21:58:58.238100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab071188",
   "metadata": {
    "papermill": {
     "duration": 1.829991,
     "end_time": "2025-03-18T21:59:03.563919",
     "exception": false,
     "start_time": "2025-03-18T21:59:01.733928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4295fe",
   "metadata": {
    "papermill": {
     "duration": 1.751486,
     "end_time": "2025-03-18T21:59:07.065857",
     "exception": false,
     "start_time": "2025-03-18T21:59:05.314371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236fdf7",
   "metadata": {
    "papermill": {
     "duration": 1.757,
     "end_time": "2025-03-18T21:59:10.548249",
     "exception": false,
     "start_time": "2025-03-18T21:59:08.791249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89dd225",
   "metadata": {
    "papermill": {
     "duration": 1.708894,
     "end_time": "2025-03-18T21:59:14.078729",
     "exception": false,
     "start_time": "2025-03-18T21:59:12.369835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40f10f",
   "metadata": {
    "papermill": {
     "duration": 1.724742,
     "end_time": "2025-03-18T21:59:17.541706",
     "exception": false,
     "start_time": "2025-03-18T21:59:15.816964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11403143,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6905307,
     "sourceId": 11079080,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1748.533934,
   "end_time": "2025-03-18T21:59:22.316642",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-18T21:30:13.782708",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
